{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anskong/ai_ref_from_lessons/blob/main/LGCNS_LangChain_031.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 간단한 Deep Research 구현 방법\n"
      ],
      "metadata": {
        "id": "J1KtkGyWjzpn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GMPPQNqIMhAq",
        "outputId": "cc17bbc6-7255-4405-dba2-0b1a04f5aee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: google-generativeai 0.8.5\n",
            "Uninstalling google-generativeai-0.8.5:\n",
            "  Successfully uninstalled google-generativeai-0.8.5\n",
            "Collecting langchain==0.3.24\n",
            "  Downloading langchain-0.3.24-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting langchain_core==0.3.55\n",
            "  Downloading langchain_core-0.3.55-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain_google_genai==2.1.3\n",
            "  Downloading langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: httpx==0.28.1 in /usr/local/lib/python3.11/dist-packages (0.28.1)\n",
            "Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Collecting langchain-tavily==0.1.5\n",
            "  Downloading langchain_tavily-0.1.5-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting langgraph==0.3.31\n",
            "  Downloading langgraph-0.3.31-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.24) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.24) (0.3.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.24) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.24) (2.0.40)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.24) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_core==0.3.55) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain_core==0.3.55) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain_core==0.3.55) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain_core==0.3.55) (4.13.2)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain_google_genai==2.1.3)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.16 (from langchain_google_genai==2.1.3)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx==0.28.1) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.28.1) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx==0.28.1) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx==0.28.1) (3.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3) (2.4.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.11.14 in /usr/local/lib/python3.11/dist-packages (from langchain-tavily==0.1.5) (3.11.15)\n",
            "Collecting mypy<2.0.0,>=1.15.0 (from langchain-tavily==0.1.5)\n",
            "  Downloading mypy-1.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph==0.3.31)\n",
            "  Downloading langgraph_checkpoint-2.0.26-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt<0.2,>=0.1.8 (from langgraph==0.3.31)\n",
            "  Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph==0.3.31)\n",
            "  Downloading langgraph_sdk-0.1.70-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: xxhash<4.0.0,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph==0.3.31) (3.5.0)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx==0.28.1) (0.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily==0.1.5) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily==0.1.5) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily==0.1.5) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily==0.1.5) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily==0.1.5) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily==0.1.5) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily==0.1.5) (1.20.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai==2.1.3) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai==2.1.3) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai==2.1.3) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai==2.1.3) (5.29.4)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core==0.3.55) (3.0.0)\n",
            "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph==0.3.31)\n",
            "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.3.31) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.24) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.24) (0.23.0)\n",
            "Collecting mypy_extensions>=1.0.0 (from mypy<2.0.0,>=1.15.0->langchain-tavily==0.1.5)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.24) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.24) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.24) (0.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.24) (3.2.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx==0.28.1) (1.3.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai==2.1.3) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai==2.1.3) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai==2.1.3) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai==2.1.3) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai==2.1.3) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai==2.1.3) (4.9.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai==2.1.3) (0.6.1)\n",
            "Downloading langchain-0.3.24-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.55-py3-none-any.whl (434 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.1/434.1 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.1.3-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_tavily-0.1.5-py3-none-any.whl (14 kB)\n",
            "Downloading langgraph-0.3.31-py3-none-any.whl (145 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.2/145.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.26-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.1.8-py3-none-any.whl (25 kB)\n",
            "Downloading langgraph_sdk-0.1.70-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy-1.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, ormsgpack, mypy_extensions, mypy, langgraph-sdk, langchain_core, langgraph-checkpoint, google-ai-generativelanguage, langgraph-prebuilt, langchain_google_genai, langchain, langgraph, langchain-tavily\n",
            "  Attempting uninstall: langchain_core\n",
            "    Found existing installation: langchain-core 0.3.59\n",
            "    Uninstalling langchain-core-0.3.59:\n",
            "      Successfully uninstalled langchain-core-0.3.59\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.25\n",
            "    Uninstalling langchain-0.3.25:\n",
            "      Successfully uninstalled langchain-0.3.25\n",
            "Successfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.18 langchain-0.3.24 langchain-tavily-0.1.5 langchain_core-0.3.55 langchain_google_genai-2.1.3 langgraph-0.3.31 langgraph-checkpoint-2.0.26 langgraph-prebuilt-0.1.8 langgraph-sdk-0.1.70 mypy-1.15.0 mypy_extensions-1.1.0 ormsgpack-1.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "61dc4bd219ac4ba294bcd1512b61d1b6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip uninstall -y google-generativeai\n",
        "!pip install langchain==0.3.24 langchain_core==0.3.55 langchain_google_genai==2.1.3 httpx==0.28.1 requests==2.32.3 langchain-tavily==0.1.5 langgraph==0.3.31"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RCEMLRLPnq24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import operator\n",
        "from typing import  Annotated\n",
        "from typing_extensions import TypedDict, Annotated\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, AnyMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_tavily import TavilySearch, TavilyExtract\n",
        "\n",
        "from langgraph.types import Command\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "from google.colab import userdata\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY_API_KEY\")"
      ],
      "metadata": {
        "id": "6eeaIB0YkFTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 정의"
      ],
      "metadata": {
        "id": "d9RWz89ZkLHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# gemini 모델\n",
        "planner_llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash-preview-05-20\", # 무료티어 종료 ㅠ_ㅠ; gemini-2.5-pro-preview-05-06\n",
        "    temperature=0,\n",
        "    max_retries=0,\n",
        ")\n",
        "\n",
        "supervisor_llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash-preview-05-20\",\n",
        "    temperature=0,\n",
        "    max_retries=0,\n",
        ")\n",
        "\n",
        "agent_llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash-preview-05-20\",\n",
        "    temperature=0,\n",
        "    max_retries=0,\n",
        ")\n",
        "\n",
        "summary_llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash-preview-05-20\", # 무료티어 종료 ㅠ_ㅠ; gemini-2.5-pro-preview-05-06\n",
        "    temperature=0,\n",
        "    max_retries=0,\n",
        ")"
      ],
      "metadata": {
        "id": "9b1277DckMpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 각 노드별 chain정의, 각노드별 프롬프트 설정, 그래프 정의"
      ],
      "metadata": {
        "id": "rssX1bLNkx7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_results = 10\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    messages: Annotated[list[AnyMessage], operator.add]\n",
        "\n",
        "class Router(BaseModel):\n",
        "    reasoning: str = Field(..., description='LLM 사고과정')\n",
        "    planning: str = Field(..., description='LLM 재개안 전략')\n",
        "    next_action: str = Field(..., description='다음 노드에서 기대하는 역할')\n",
        "    next: str = Field(..., description='다음 노드의 전환 대상')\n",
        "\n",
        "# Initialize Tavily Search Tool\n",
        "tavily_search_tool = TavilySearch(\n",
        "    max_results=search_results,\n",
        "    topic=\"general\",\n",
        ")\n",
        "tavily_extract_tool = TavilyExtract()\n",
        "\n",
        "tools = [\n",
        "    tavily_search_tool,\n",
        "    tavily_extract_tool\n",
        "]\n",
        "\n",
        "planner_system_message = [\n",
        "    SystemMessage(\n",
        "        content=\"\"\"\n",
        "# 목적\n",
        "당신은 신뢰할 수 있는 한국어 AI 어시스턴트입니다.\n",
        "질문에 대해 먼저 사고 과정을 설명하고, 그 뒤에 결론을 제시해 주세요.\n",
        "당신의 역할은, 사용자의 질문에 어떤 전략으로 접근해야 최적의 답변이 가능한지 **\"전략을 설계\"**하는 것입니다.\n",
        "\n",
        "# 지시\n",
        "우리는 \"tavily_search_tool\"과 \"tavily_extract_tool\"이라는 두 가지 도구를 가지고 있습니다.\n",
        "사용자의 질문에 대해 어떤 도구를 사용하여 어떻게 대답하는 것이 가장 효율적인지 생각합니다.\n",
        "또한, 사용자의 질문을 회답하기 위해서 필요한 정보가 다방면에 걸치고 있는 경우, 모두를 한 번에 조사하는 것이 아니라, 태스크를 분해해, 하나하나 조사를 해 주세요.\n",
        "이러한 전략을 결정하고 후단의 에이전트가 수행하는 작업이 최소 구성이 되도록 분할·전략 입안하는 것이 당신의 중요한 역할입니다.\n",
        "또한, 사용자가 스스로 선정을 할 수 있도록, 유저에게는 조사 결과로서 4개 이상의 선택사항을 제시할 수 있는 단지 하나의 전략을 입안해 주세요.\n",
        "(즉, 복수의 후보를 씻어내고, 선정의 도중에 유저의 의도에 맞지 않는 것이 판명되었을 때에는, 새로운 선택사항을 조사할 필요도 있어.처음부터 그것을 예측해 많은 선택지를 미리 씻어낼 필요가 있습니다.)\n",
        "\n",
        "# 실행절차\n",
        "1. 사용자의 질문에 대해 어떤 전략으로 질문에 답변해야 하는지 생각해 보십시오.\n",
        "2. 사용자의 질문에 대해 어떤 도구를 사용하여 어떻게 대답하는 것이 가장 효율적인지 생각하십시오.\n",
        "3. 사용자의 질문을 답하기 위해 필요한 정보가 다양하게 넘어가는 경우, 모든 것을 한 번에 조사하는 것이 아니라, 태스크를 분해해, 하나하나 조사를 하는 전략을 세웁니다.\n",
        "4. 최종적으로는 유저가 요구하는 내용을 복수 제시해, 유저가 선택할 수 있도록, '5개 이상'의 선택사항을 제시하고 싶습니다.그것이 가능하게 되도록 미리 깊은 조사를 하기전의 리스트 업을 몇개 실시해, 어떻게 리스트 업 해야 하는지 전략을 세웁니다.\n",
        "5. 이러한 전략을 결정하고, 후단의 에이전트가 수행하는 태스크가 최소 구성이 되도록 분할·전략 입안합니다.\n",
        "6. 생각한 결과를 마지막으로 정리해 전략으로 합니다.\n",
        "\n",
        "# 주의사항\n",
        "당신은 단지 전략을 수립하기 때문에 도구를 실행할 수 없습니다.\n",
        "\"\"\"\n",
        "    ),\n",
        "    MessagesPlaceholder(\"messages\"),\n",
        "]\n",
        "\n",
        "superviser_system_message = [\n",
        "    SystemMessage(\n",
        "        content=\"\"\"\n",
        "# 목적\n",
        "당신은 유용한 한국어 AI 어시스턴트입니다.\n",
        "사용자의 질문과, 과거에 검토한 해결을 위한 전략을 바탕으로, 현재의 조사 결과로 충분한지 어떤지를 판단해, 다음에 어느 노드에 천이할까를 생각합니다.\n",
        "\n",
        "# 지시\n",
        "우리는 \"tavily_search_tool\"과 \"tavily_extract_tool\"이라는 두 가지 도구를 가지고 있습니다.\n",
        "tavily_search_tool은 Google 검색을 수행하고 상위 xx 개의 URL과 개요를 얻는 도구입니다.\n",
        "tavily_extract_tool은 URL을 지정하여 페이지의 내용을 추출하는 도구입니다.\n",
        "또한, 지금까지의 처리 속에서, 사용자의 질문에 대해, 어떠한 전략으로 그 질문에 회답할지 어떨지의 전략을 입안해, 그 조사도 진행하고 있을지도 모릅니다.\n",
        "당신은 사용자의 질문과 지금까지의 조사 결과, 조사 전략을 모두 고려한 다음, 다음에 어느 노드로 천이해야 할지를 생각합니다.\n",
        "그러나 당신은 어디까지나 전환 대상 노드를 출력하기 때문에 도구를 실행할 수 없습니다.\n",
        "\n",
        "# 실행절차\n",
        "1. 현재의 조사 결과 등으로부터, 다음의 어느 노드가 어떤 태스크를 실행해야 하는지를 생각합니다.\n",
        "2. 다음으로 [\"agent\", \"summary\"]의 어느 노드로 전환해야 하는지를 고려합니다.\n",
        "\n",
        "# 전환 대상을 결정하는 규칙\n",
        "- agent: 기존의 정보만으로는 유저가 만족하는 응답을 출력할 수 없는 경우, agent 노드의 천이합니다.이 때 반드시 agent 노드에 어떤 처리를 기대하는지를 'next_action'필드에 출력해 주세요.\n",
        "- summary : 사용자의 질문에 대해 충분한 정보가 얻어지면 summary 노드로 천이합니다.\n",
        "다음의 에이전트는, 'next_action'필드에 기재된 내용 밖에 파악하지 않기 때문에, 그 전제로 다음의 에이전트가 실행하는데 필요한 처리는 모두 'next_action'필드에 기재해 주세요.\n",
        "\n",
        "그러나 매우 중요한 것은 조사가 다면적인 관점에서 수행되어야 합니다.\n",
        "그러므로 겉보기에 여러 설문조사 결과를 얻은 경우에도 결과가 일부만 표시되는 경우 agent에 추가 설문조사를 하도록 합니다.\n",
        "최소한 10개가 넘는 웹페이지에 대해 다면적인 검색어로 설문조사를 수행하십시오.\n",
        "또한 하나의 검색 워드에 중에서 얻은 정보에서 추가로 검색하여 새로운 정보를 얻을 수 있습니다.\n",
        "전체 문장 취득하고 있는 web 페이지의 내용 밖에 신용하지 말아 주세요.최소라도 10 이상의 Web 페이지의 전문 취득이 되어 있지 않은 경우, agent 노드에 추가 조사를 시켜 주세요.\n",
        "또, 필요한 정보가 모두 취득되어 있다고 느꼈을 경우, 유저의 질문을 재검토해, 관련해 유저가 요구할 정보를 미리 검토해, 그 내용에 대해서도 마찬가지로 조사를 실시해 주세요.\n",
        "또한 과거 시행 중 같은 도구를 비슷한 검색결과로 두드리는 경우에는 Agents가 혼란스럽고 잘 조사되지 않았기 때문에 여기에서 어떤 형태로 검색하는 것이 좋은지를 다른 각도로 제안해 주세요.\n",
        "조사는 미세한 작업으로 나누고 단계별로 해결해야 한다는 점을 항상 염두에 두고 검토해야 합니다.\n",
        "\n",
        "# 주의사항\n",
        "당신은 단지 전략을 수립하기 때문에 도구를 실행할 수 없습니다.\n",
        "사용자의 질문에는 항상 충실해야 합니다. **조사 결과에서 사용자의 질문에 대답하기에 충분하지 않은 경우에는 반드시 agent를 호출하고 summary를 호출하지 마십시오.**\n",
        "\n",
        "# 제약사항\n",
        "당신은 \"Router\"클래스로 구조화 된 출력을 발행합니다.\n",
        "반드시 \"reasoning\"과 \"next\"라는 두 개의 필드가 있어야 합니다.\n",
        "- reasoning: 여러분이 생각한 이유를 출력해 주세요. 여기는 매우 상세하고 긴 문장으로 출력되고 있을 필요가 있습니다. 여기에 있는 정보가 사용자의 질문 내용을 정확하고 상세하게 대답할 수 있을지 어떨지를 판단해 주세요.\n",
        "- planning: 지금까지의 설문 조사 결과를 바탕으로 초기 설정 전략과 사용자 입력 및 설문 조사 결과를 고려하여 최종 출력을 얻기위한 전략을 재정의하십시오. 이러한 전략을 세우는 데 집중하십시오. 입안 형식은 가장 먼저 전략 입안 Agents의 출력 결과를 참조하십시오.\n",
        "- next_action: 당신이 생각한 다음 노드의 역할을 출력하십시오. 여기서는 사용자의 질문과 첫 번째 전략에서 다음 노드가 어떤 역할을 수행해야하는지 생각해보십시오. 지금 가지고 있는 정보와 부족점으로부터 다음의 전략을 특정해, 다음의 노드가 어떤 처리를 해야 하는지를 생각해 여기에 기재해 주세요.여기에 기재되는 내용은 가능한 한 작은 영역을 고려하는 태스크인 것이 바람직합니다. 「각각의」나 「검색한 결과로부터」등의 추상도가 높은 단어는 사용하는데, 그대로 검색을 할 수 있을 정도의 구체성이 높은 검색 키워드를 기재해 주세요. 키워드가 아닌 보다 작은 단위로 분해한 최소 구성의 검색 워드이며, 구체적으로 취득할 수 있는 정보 범위가 좁아지는 검색 키워드를 검토해 주세요.실행에 복수의 선택사항이 있는 경우는 반드시 하나로 좁혀 주세요\n",
        "- next: 당신이 생각한 다음 노드를 출력합니다. [\"agent\", \"summary\"]\n",
        "\"\"\"\n",
        "    ),\n",
        "    MessagesPlaceholder(\"messages\"),\n",
        "]\n",
        "\n",
        "agent_system_message = [\n",
        "    SystemMessage(\n",
        "        content=\"\"\"\n",
        "# 목적\n",
        "당신은 유용한 한국어 AI 어시스턴트입니다.\n",
        "사용자의 질문, 과거에 검토한 해결을 위한 전략과 이전 단계의 예상되는 처리를 바탕으로 툴을 실행합니다.\n",
        "\n",
        "# 지시\n",
        "우리는 \"tavily_search_tool\"과 \"tavily_extract_tool\"이라는 두 가지 도구를 가지고 있습니다.\n",
        "tavily_search_tool은 Google 검색을 수행하고 상위 5 개의 URL과 개요를 얻는 도구입니다.\n",
        "tavily_extract_tool은 URL을 지정하여 페이지의 내용을 추출하는 도구입니다.\n",
        "적절하게 사용하여 사용자의 질문에 답변하십시오.\n",
        "항상 뭔가 도구를 실행해야합니다.\n",
        "우선, 사용자의 질문으로부터 툴을 어떤 의도로 몇번 이용하지 않으면 안 되는지를 판단해, 필요하면 복수회 tool를 이용해 정보 수집을 실시해 주세요.\n",
        "\n",
        "# 실행 절차\n",
        "1. 전단의 기대되는 처리를 참고해, 어느 툴을 어느 인수로 실행할까를 검토해, 툴을 실행해 주세요.\n",
        "2. 이때 하나의 검색 후보뿐만 아니라 **관련된 복수의 검색 후보를 검토**한 다음 툴을 실행해 주십시오.\n",
        "3. 도구의 실행 결과를 바탕으로 사용자의 질문에 대해 어떤 정보를 얻었는지 생각하십시오.\n",
        "4. 툴의 실행 결과를 바탕으로, 최종적으로 어떤 결과가 얻어졌는지를 정리해 출력합니다.\n",
        "\n",
        "# 주의사항\n",
        "출력 결과에는 반드시 출처를 포함해야 합니다.\n",
        "출처는 도구의 실행 결과에 포함된 페이지의 제목과 URL을 그대로 인용하십시오.\n",
        "인용할 때는 문장에 직접 페이지의 URL을 묻어 주세요.그 위에 문장의 마지막에 출전의 타이틀과 URL을 정리해 출력해 주세요.\n",
        "숫자([1], *1 등)로 출처를 인용하는 것은 **금지**합니다.\n",
        "\n",
        "\"\"\"\n",
        "    ),\n",
        "    MessagesPlaceholder(\"messages\"),\n",
        "]\n",
        "\n",
        "summary_system_message = [\n",
        "    SystemMessage(\n",
        "        content=\"\"\"\n",
        "# 목적\n",
        "당신은 유용한 한국어 AI 어시스턴트입니다.\n",
        "유저의 질문과, 과거에 검토한 해결을 위한 전략과, 전단의 기대되는 처리를 바탕으로, 지금까지의 조사 결과를 모두 정리해 유저에게 제시합니다.\n",
        "보고서는 조사한 내용을 최대한 자세히 설명해 주시기 바랍니다.\n",
        "\n",
        "# # 지시\n",
        "유저의 질문 내용에 맞추어, 지금까지의 조사 결과를 모두 정리해 유저에게 제시해 주세요.\n",
        "**사용자의 질문 내용을 한 번 되돌아 본 후**에, **지금까지의 조사 결과를 모두 고려**한 다음, 리포트 형식으로 출력해 주세요.\n",
        "또한, 사용자가 스스로 선정할 수 있도록 반드시 **5개 이상**의 복수의 선택사항을 제시해 주십시오.\n",
        "출력은 유저에게 다가가, 알기 쉬운 형태로 실시해 주세요.\n",
        "\n",
        "# 주의사항\n",
        "출력은 markdown 형식으로 실시해, 정기적으로 개행을 넣는 등 보기 쉬운 형태로 표시해 주세요.\n",
        "그러나 출력 전체에 코드 블록(```)을 사용하지 마십시오.\n",
        "\n",
        "출력 결과에는 반드시 출처를 포함해야 합니다.\n",
        "출처는 도구의 실행 결과에 포함된 페이지의 제목과 URL을 그대로 인용하십시오.\n",
        "인용할 때는 문장에 직접 페이지의 URL을 묻어 주세요.그 위에 문장의 마지막에 출전의 타이틀과 URL을 정리해 출력해 주세요.\n",
        "숫자([1], *1 등)로 출처를 인용하는 것은 **금지**합니다.\n",
        "\n",
        "\"\"\"\n",
        "    ),\n",
        "    MessagesPlaceholder(\"messages\"),\n",
        "]\n",
        "\n",
        "supervisor_prompt = ChatPromptTemplate.from_messages(superviser_system_message)\n",
        "agent_prompt = ChatPromptTemplate.from_messages(agent_system_message)\n",
        "planner_prompt = ChatPromptTemplate.from_messages(planner_system_message)\n",
        "summary_prompt = ChatPromptTemplate.from_messages(summary_system_message)\n",
        "\n",
        "supervisor_chain = supervisor_prompt | supervisor_llm.with_structured_output(Router)\n",
        "agent_chain = agent_prompt | agent_llm.bind_tools(tools)\n",
        "planner_chain = planner_prompt | planner_llm\n",
        "summary_chain = summary_prompt | summary_llm\n",
        "\n",
        "def create_graph(tools):\n",
        "\n",
        "    def prediction_agent(chain, message):\n",
        "        #gemini는 rate limit에 의한 에러가 발생할 수 있으므로, 재시도 처리를 추가\n",
        "        while True:\n",
        "            try:\n",
        "                response = chain.invoke(message)\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(\"Error:\", e)\n",
        "                print(\"Retrying...\")\n",
        "                time.sleep(61)\n",
        "        return response\n",
        "\n",
        "    def should_continue(state: GraphState):\n",
        "        messages = state[\"messages\"]\n",
        "        last_message = messages[-1]\n",
        "        if last_message.tool_calls:\n",
        "            print(\"====tool_calls====\")\n",
        "            print(last_message.tool_calls)\n",
        "            return \"tools\"\n",
        "        return \"supervisor\"\n",
        "\n",
        "    def call_planner(state: GraphState):\n",
        "        messages = state[\"messages\"]\n",
        "        response = prediction_agent(planner_chain, messages)\n",
        "        print(\"====planner====\")\n",
        "        print(response.content)\n",
        "        return {\"messages\": [response]}\n",
        "\n",
        "    def call_supervisor(state: GraphState):\n",
        "        messages = state[\"messages\"]\n",
        "        response = prediction_agent(supervisor_chain, messages)\n",
        "\n",
        "        print(\"====supervisor====\")\n",
        "        print(\"reasoning:\", response.reasoning)\n",
        "        print(\"next action:\", response.next_action)\n",
        "        print(\"next agent:\", response.next)\n",
        "\n",
        "        goto = response.next\n",
        "        return Command(goto=goto, update={\"messages\": [AIMessage(content=response.next_action, name=\"supervisor\")]})\n",
        "\n",
        "    def call_summary(state: GraphState):\n",
        "        messages = state[\"messages\"]\n",
        "        messages[-1] = HumanMessage(content=messages[-1].content)\n",
        "        response = prediction_agent(summary_chain, messages)\n",
        "        return {\"messages\": [response]}\n",
        "\n",
        "    def call_agent(state: GraphState):\n",
        "        messages = state[\"messages\"]\n",
        "        print(\"\\n====call_agent====\")\n",
        "\n",
        "        input_messages_for_agent: List[AnyMessage] = []\n",
        "        latest_instruction_message_idx = -1\n",
        "\n",
        "        for i in range(len(messages) - 1, -1, -1):\n",
        "            msg = messages[i]\n",
        "\n",
        "            if (isinstance(msg, AIMessage) and\n",
        "                hasattr(msg, 'name')):\n",
        "                next_action = getattr(msg, 'name', None)\n",
        "                # 발견 된 첫 번째 AIMessage 인덱스가 슬라이스의 시작점\n",
        "                if next_action==\"supervisor\":\n",
        "                    latest_instruction_message_idx = i\n",
        "                    break # 최신 지시 메시지 (라고 가정하는 AIMessage)를 찾았으므로 검색 종료\n",
        "\n",
        "        if latest_instruction_message_idx != -1:\n",
        "            # 슬라이스 시작 인덱스는 지시 메시지 자체의 인덱스\n",
        "            start_slice_idx = latest_instruction_message_idx\n",
        "            input_messages_for_agent = messages[start_slice_idx:]\n",
        "        else:\n",
        "            input_messages_for_agent = messages\n",
        "\n",
        "        input_messages_for_agent[0] = HumanMessage(content=input_messages_for_agent[0].content)\n",
        "        print(\"Agent에 대한 입력 메시지:\", input_messages_for_agent)\n",
        "\n",
        "        response = prediction_agent(agent_chain, {\"messages\": input_messages_for_agent})\n",
        "\n",
        "        print(\"====agent response====\")\n",
        "        print(response)\n",
        "        # Agent응답 (도구 호출을 포함하거나 텍스트 응답)을 State의 messages 목록 전체에 추가\n",
        "        return {\"messages\": [response]}\n",
        "\n",
        "    tool_node = ToolNode(tools)\n",
        "    workflow = StateGraph(GraphState)\n",
        "    workflow.add_node(\"planner\", call_planner)\n",
        "    workflow.add_node(\"supervisor\", call_supervisor)\n",
        "    workflow.add_node(\"summary\", call_summary)\n",
        "    workflow.add_node(\"agent\", call_agent)\n",
        "    workflow.add_node(\"tools\", tool_node)\n",
        "\n",
        "    workflow.add_edge(START, \"planner\")\n",
        "    workflow.add_edge(\"planner\", \"supervisor\")\n",
        "    workflow.add_conditional_edges(\"agent\", should_continue, [\"tools\", \"supervisor\"])\n",
        "    workflow.add_edge(\"tools\", \"agent\")\n",
        "    workflow.add_edge(\"summary\", END)\n",
        "    memory = MemorySaver()\n",
        "    app = workflow.compile(checkpointer=memory)\n",
        "\n",
        "    return app\n",
        "\n",
        "graph = create_graph(tools)\n",
        "\n",
        "from IPython.display import Image, display\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "5d4evbHmkyTf",
        "outputId": "99f2126c-21a7-4687-8d06-96b8e1a4da49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DeepResearch 실행"
      ],
      "metadata": {
        "id": "-l7rS2ARnQcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph_config = {\"recursion_limit\": 20000, \"configurable\": {\"thread_id\": \"12345\"}}\n",
        "while True:\n",
        "    query = input(\"입력: \")\n",
        "\n",
        "    if query.lower() in [\"exit\", \"quit\"]:\n",
        "        print(\"종료합니다.\")\n",
        "        break\n",
        "\n",
        "    input_query = [HumanMessage(\n",
        "            [\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": f\"{query}\"\n",
        "                },\n",
        "            ]\n",
        "        )]\n",
        "\n",
        "    response = graph.invoke({\"messages\":input_query}, graph_config)\n",
        "\n",
        "    #디버그용\n",
        "    print(\"response: \", response)\n",
        "\n",
        "    # 최종답변\n",
        "    print(\"=================================\")\n",
        "    print(response[\"messages\"][-1].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HSH_CvuLnQ2c",
        "outputId": "d8309797-12c5-4be5-c902-022231e0429d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력: tool calling\n",
            "====planner====\n",
            "## 전략 수립\n",
            "\n",
            "사용자께서는 \"tool calling\"에 대해 질문하셨습니다. 이는 AI 모델의 중요한 기능 중 하나이므로, 단순히 개념을 설명하는 것을 넘어, 실제 활용 방법과 다양한 사례를 제시하여 사용자가 스스로 최적의 선택을 할 수 있도록 돕는 것이 중요합니다.\n",
            "\n",
            "**목표:** AI 모델에서 'tool calling'을 효과적으로 사용하는 방법과 주요 활용 사례를 **5가지 이상**의 선택지로 제시합니다.\n",
            "\n",
            "**전략:**\n",
            "\n",
            "1.  **광범위한 초기 조사 (tavily_search_tool 활용):**\n",
            "    *   'tool calling'의 기본 개념, 작동 원리, 주요 이점, 그리고 가장 일반적인 활용 분야 및 관련 프레임워크(예: OpenAI Function Calling, LangChain Tools)에 대한 정보를 광범위하게 검색합니다.\n",
            "    *   **검색 쿼리 예시:**\n",
            "        *   \"AI 모델 tool calling 개념 및 활용 사례\"\n",
            "        *   \"LLM tool calling 사용법\"\n",
            "        *   \"OpenAI Function Calling 예시\"\n",
            "        *   \"LangChain Tools 활용\"\n",
            "    *   **목표:** 이 단계에서 다양한 활용 분야(예: 실시간 정보 검색, 외부 API 연동, 데이터베이스 조회, 코드 실행 등)와 구현 방식에 대한 개요를 파악하여, 사용자에게 제시할 5가지 이상의 선택지 후보군을 확보합니다.\n",
            "\n",
            "2.  **선택지 후보군 분류 및 구체화:**\n",
            "    *   초기 조사 결과에서 얻은 정보를 바탕으로, 'tool calling'의 다양한 측면을 대표할 수 있는 5가지 이상의 명확하고 독립적인 선택지(또는 활용 사례/방법)를 분류합니다.\n",
            "    *   **예상되는 선택지 후보군:**\n",
            "        1.  **개념 및 기본 작동 원리:** Tool Calling이 무엇이며 어떻게 작동하는지.\n",
            "        2.  **실시간 정보 검색 및 웹 서핑:** 최신 정보나 특정 웹사이트 내용을 가져오는 방법.\n",
            "        3.  **외부 API 연동:** 날씨, 주식, 예약 시스템 등 외부 서비스와 연동하는 방법.\n",
            "        4.  **데이터베이스 조회 및 조작:** 사내 데이터베이스나 특정 데이터셋에서 정보를 검색하거나 업데이트하는 방법.\n",
            "        5.  **복잡한 계산 및 코드 실행:** 파이썬 코드 실행, 통계 분석 등 복잡한 연산을 수행하는 방법.\n",
            "        6.  **특정 프레임워크(OpenAI Function Calling, LangChain 등) 활용:** 각 프레임워크에서 Tool Calling을 구현하는 구체적인 방식.\n",
            "        7.  **Tool Calling 설계 및 최적화 Best Practice:** 효과적인 Tool Calling을 위한 설계 원칙 및 팁.\n",
            "    *   **목표:** 이 단계에서 최소 5개 이상의 구체적인 선택지를 확정합니다.\n",
            "\n",
            "3.  **선택지별 상세 정보 추출 (tavily_extract_tool 활용 - 필요시):**\n",
            "    *   2단계에서 확정한 각 선택지에 대해, 초기 조사에서 얻은 URL 중 가장 관련성이 높고 상세한 정보를 담고 있는 페이지를 식별합니다.\n",
            "    *   **필요시:** 해당 URL에 대해 `tavily_extract_tool`을 사용하여 페이지의 전체 내용을 추출합니다. 이는 각 선택지에 대한 깊이 있는 설명이나 구체적인 예시를 제공하는 데 사용됩니다. 모든 선택지에 대해 추출 도구를 사용할 필요는 없으며, 초기 검색 결과만으로 충분한 경우도 있습니다.\n",
            "    *   **목표:** 각 선택지에 대한 충분한 정보를 확보하여 사용자가 이해하고 비교할 수 있도록 합니다.\n",
            "\n",
            "4.  **정보 종합 및 5가지 이상 선택지 제시:**\n",
            "    *   수집된 모든 정보를 바탕으로, 각 선택지에 대한 간결하고 명확한 설명을 작성합니다.\n",
            "    *   사용자가 각 선택지의 특징과 활용 가능성을 쉽게 파악할 수 있도록 구성합니다.\n",
            "    *   **최종 결과물 예시 구성:**\n",
            "        *   **1. Tool Calling의 기본 개념 이해:** (개념 설명)\n",
            "        *   **2. 실시간 정보 검색 및 웹 서핑 활용:** (활용 사례 및 예시)\n",
            "        *   **3. 외부 API 연동을 통한 서비스 확장:** (활용 사례 및 예시)\n",
            "        *   **4. 데이터베이스 연동으로 정보 활용 극대화:** (활용 사례 및 예시)\n",
            "        *   **5. 복잡한 계산 및 코드 실행 자동화:** (활용 사례 및 예시)\n",
            "        *   **6. 주요 프레임워크별 Tool Calling 구현 방식:** (OpenAI, LangChain 등 비교)\n",
            "    *   **목표:** 사용자가 'tool calling'의 다양한 측면을 이해하고, 자신의 필요에 맞는 활용 방안을 선택할 수 있도록 돕는 5가지 이상의 명확한 선택지를 제공합니다.\n",
            "\n",
            "이 전략은 `tavily_search_tool`을 통해 넓은 범위의 정보를 효율적으로 수집하고, 필요한 경우에만 `tavily_extract_tool`을 사용하여 깊이 있는 정보를 얻음으로써, 후속 에이전트의 작업량을 최소화하면서도 사용자에게 풍부하고 유용한 정보를 제공할 수 있도록 설계되었습니다.\n",
            "====supervisor====\n",
            "reasoning: 사용자의 질문은 \"tool calling\"에 대한 것입니다. 이 질문에 대해 단순히 개념을 설명하는 것을 넘어, 실제 활용 방법과 다양한 사례를 제시하여 사용자가 스스로 최적의 선택을 할 수 있도록 돕는 것이 중요하다고 판단했습니다. 따라서, AI 모델에서 'tool calling'을 효과적으로 사용하는 방법과 주요 활용 사례를 5가지 이상의 선택지로 제시하는 것을 목표로 설정했습니다. 이를 위해 먼저 광범위한 초기 조사를 통해 'tool calling'의 기본 개념, 작동 원리, 주요 이점, 일반적인 활용 분야 및 관련 프레임워크에 대한 정보를 수집해야 합니다. 이 과정에서 다양한 검색 쿼리를 사용하여 최소 10개 이상의 웹페이지에서 정보를 얻고, 각 웹페이지의 전체 내용을 추출하여 충분한 정보를 확보하는 것이 중요합니다. 이렇게 수집된 정보를 바탕으로 'tool calling'의 다양한 측면을 대표할 수 있는 5가지 이상의 명확하고 독립적인 선택지를 분류하고 구체화할 수 있을 것입니다. 현재는 초기 정보 수집 단계이므로, agent 노드로 전환하여 필요한 정보를 검색하고 추출하는 작업을 수행해야 합니다. 이 정보가 충분히 수집되면 다음 단계에서 선택지를 분류하고 상세화하는 작업을 진행할 수 있습니다.\n",
            "next action: AI 모델의 \"tool calling\"에 대한 기본 개념, 작동 원리, 주요 이점, 그리고 가장 일반적인 활용 분야 및 관련 프레임워크(예: OpenAI Function Calling, LangChain Tools)에 대한 정보를 광범위하게 검색하여 최소 10개 이상의 웹페이지에서 정보를 수집하고, 각 웹페이지의 전체 내용을 추출하여 \"tool calling\"의 다양한 측면을 대표할 수 있는 5가지 이상의 명확하고 독립적인 선택지(또는 활용 사례/방법)를 분류할 수 있는 충분한 정보를 확보합니다. 특히, \"AI 모델 tool calling 개념 및 활용 사례\", \"LLM tool calling 사용법\", \"OpenAI Function Calling 예시\", \"LangChain Tools 활용\" 등의 검색 쿼리를 사용하여 다양한 관점의 정보를 수집합니다.\n",
            "next agent: agent\n",
            "\n",
            "====call_agent====\n",
            "Agent에 대한 입력 메시지: [HumanMessage(content='AI 모델의 \"tool calling\"에 대한 기본 개념, 작동 원리, 주요 이점, 그리고 가장 일반적인 활용 분야 및 관련 프레임워크(예: OpenAI Function Calling, LangChain Tools)에 대한 정보를 광범위하게 검색하여 최소 10개 이상의 웹페이지에서 정보를 수집하고, 각 웹페이지의 전체 내용을 추출하여 \"tool calling\"의 다양한 측면을 대표할 수 있는 5가지 이상의 명확하고 독립적인 선택지(또는 활용 사례/방법)를 분류할 수 있는 충분한 정보를 확보합니다. 특히, \"AI 모델 tool calling 개념 및 활용 사례\", \"LLM tool calling 사용법\", \"OpenAI Function Calling 예시\", \"LangChain Tools 활용\" 등의 검색 쿼리를 사용하여 다양한 관점의 정보를 수집합니다.', additional_kwargs={}, response_metadata={})]\n",
            "====agent response====\n",
            "content='' additional_kwargs={'function_call': {'name': 'tavily_search', 'arguments': '{\"search_depth\": \"advanced\", \"query\": \"AI \\\\ubaa8\\\\ub378 tool calling \\\\uac1c\\\\ub150 \\\\ubc0f \\\\ud65c\\\\uc6a9 \\\\uc0ac\\\\ub840\"}'}} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'models/gemini-2.5-flash-preview-05-20', 'safety_ratings': []} id='run-d1ac2b25-faf2-46e3-bf26-008fc6415994-0' tool_calls=[{'name': 'tavily_search', 'args': {'search_depth': 'advanced', 'query': 'AI 모델 tool calling 개념 및 활용 사례'}, 'id': '37ba0fa2-66d5-4d38-b76d-5cbf54ccc37b', 'type': 'tool_call'}] usage_metadata={'input_tokens': 1477, 'output_tokens': 31, 'total_tokens': 1824, 'input_token_details': {'cache_read': 0}}\n",
            "====tool_calls====\n",
            "[{'name': 'tavily_search', 'args': {'search_depth': 'advanced', 'query': 'AI 모델 tool calling 개념 및 활용 사례'}, 'id': '37ba0fa2-66d5-4d38-b76d-5cbf54ccc37b', 'type': 'tool_call'}]\n",
            "\n",
            "====call_agent====\n",
            "Agent에 대한 입력 메시지: [HumanMessage(content='AI 모델의 \"tool calling\"에 대한 기본 개념, 작동 원리, 주요 이점, 그리고 가장 일반적인 활용 분야 및 관련 프레임워크(예: OpenAI Function Calling, LangChain Tools)에 대한 정보를 광범위하게 검색하여 최소 10개 이상의 웹페이지에서 정보를 수집하고, 각 웹페이지의 전체 내용을 추출하여 \"tool calling\"의 다양한 측면을 대표할 수 있는 5가지 이상의 명확하고 독립적인 선택지(또는 활용 사례/방법)를 분류할 수 있는 충분한 정보를 확보합니다. 특히, \"AI 모델 tool calling 개념 및 활용 사례\", \"LLM tool calling 사용법\", \"OpenAI Function Calling 예시\", \"LangChain Tools 활용\" 등의 검색 쿼리를 사용하여 다양한 관점의 정보를 수집합니다.', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'function_call': {'name': 'tavily_search', 'arguments': '{\"search_depth\": \"advanced\", \"query\": \"AI \\\\ubaa8\\\\ub378 tool calling \\\\uac1c\\\\ub150 \\\\ubc0f \\\\ud65c\\\\uc6a9 \\\\uc0ac\\\\ub840\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'models/gemini-2.5-flash-preview-05-20', 'safety_ratings': []}, id='run-d1ac2b25-faf2-46e3-bf26-008fc6415994-0', tool_calls=[{'name': 'tavily_search', 'args': {'search_depth': 'advanced', 'query': 'AI 모델 tool calling 개념 및 활용 사례'}, 'id': '37ba0fa2-66d5-4d38-b76d-5cbf54ccc37b', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1477, 'output_tokens': 31, 'total_tokens': 1824, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='{\"query\": \"AI 모델 tool calling 개념 및 활용 사례\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://dytis.tistory.com/98\", \"title\": \"LangChain을 활용한 Tool Calling # 3 - DEV.DY - 티스토리\", \"content\": \"Tool Calling의 개념 ... Tool Calling은 말 그대로 특정 작업을 수행할 수 있는 툴을 호출하는 것을 의미합니다. 예를 들어, AI가 날씨 정보를 제공해야 할\", \"score\": 0.8138313, \"raw_content\": null}, {\"url\": \"https://digitalbourgeois.tistory.com/885\", \"title\": \"Spring AI의 새로운 도구 호출 기능: AI와 API의 강력한 연동 방법!\", \"content\": \"Tool Calling(도구 호출)은 AI 모델이 특정 API나 도구를 직접 호출하여 데이터를 가져오거나 연산을 수행할 수 있도록 지원하는 기능입니다. ✓ 이전 방식\", \"score\": 0.8029425, \"raw_content\": null}, {\"url\": \"https://dytis.tistory.com/95\", \"title\": \"LLM 어플리케이션에서의 Tool Calling: AI가 더 똑똑해지는 방법\", \"content\": \"OpenAI CookBook에서 소개하는 Tool calling의 실제 적용 사례는 쇼핑 어시스턴트, 고객 서비스 에이전트, 그리고 인터랙티브 예약 경험입니다. 쇼핑\", \"score\": 0.798643, \"raw_content\": null}, {\"url\": \"https://claremont.tistory.com/entry/%EC%83%9D%EC%84%B1%ED%98%95-AI-LLM%EC%9D%98-Tool-Calling%EB%8F%84%EA%B5%AC-%ED%98%B8%EC%B6%9C%EC%9D%B4%EB%9E%80\", \"title\": \"[생성형 AI] LLM의 Tool Calling(도구 호출)이란? - Go for IT - 티스토리\", \"content\": \"Tool Calling은 LLM이 외부 도구를 활용하여 보다 정확하고 신뢰할 수 있는 응답을 생성하는 기술이다. 이를 통해 최신 정보를 반영하고, 연산을 수행하며\", \"score\": 0.685971, \"raw_content\": null}, {\"url\": \"https://velog.io/@byu0hyun/AIMessage-ToolMessage-Tool-Calling-%ED%9D%90%EB%A6%84-%EC%9D%B4%ED%95%B4\", \"title\": \"AIMessage, ToolMessage, Tool Calling 흐름 이해 - velog\", \"content\": \"AIMessage, ToolMessage, Tool Calling 흐름 이해\\\\n\\\\nAIMessage, ToolMessage, Tool Calling 완벽 이해: AIMessage → ToolMessage → AIMessage 흐름\\\\n\\\\nAI 기반의 챗봇이나 자동화 시스템을 설계할 때, 단순히 모델이 답변을 생성하는 것이 아니라 외부 API, 데이터베이스, 코드 실행 등의 툴(Tool)을 호출해야 하는 경우가 많습니다.\\\\n이때 Tool Calling(툴 호출) 개념이 사용되며, 대표적으로 OpenAI의 Function Calling이나 LangChain의 Tool 기능이 있습니다.\\\\n\\\\n오늘은 Tool Calling의 핵심 흐름인 AIMessage → ToolMessage → AIMessage 구조를 이해하고, tool_calls 필드가 왜 중요한지 살펴보겠습니다.\\\\n\\\\n1. AIMessage → ToolMessage → AIMessage 흐름이란? [...] Tool Calling 과정에서 메시지는 다음과 같은 흐름을 따릅니다.\\\\n\\\\n① AIMessage (툴 호출 요청)\\\\n\\\\n사용자의 질문을 받은 LLM이 자체적으로 답변을 생성하지 않고, 외부 툴을 호출해야 한다고 판단하면 tool_calls 필드를 포함한 메시지를 생성합니다.\\\\n이때 중요한 점은 LLM이 직접 툴을 실행하는 것이 아니라, 툴을 호출하는 요청만 만든다는 것입니다.\\\\n\\\\n🔹 예제 (AIMessage - Tool 호출 요청)\\\\n\\\\n✔ \\\\\"get_weather\\\\\"라는 툴을 호출해야 함을 나타냄.\\\\n✔ \\\\\"location\\\\\": \\\\\"Seoul\\\\\" 값을 툴에 전달하도록 요청함.\\\\n✔ LLM은 툴을 직접 실행하지 않고, 툴을 호출하는 요청만 생성.\\\\n\\\\n즉, tool_calls이 포함된 AIMessage는 반드시 툴을 실행해야 하며, 툴이 실행되지 않으면 LLM은 후속 응답을 생성할 수 없습니다.\\\\n\\\\n② ToolMessage (툴 실행 및 결과 반환) [...] AIMessage에서 툴을 호출했으므로, 실제 툴이 실행되고 결과를 반환해야 합니다.\\\\n이 역할을 하는 것이 ToolMessage이며, 툴의 실행 결과를 담고 있습니다.\\\\n\\\\n🔹 예제 (ToolMessage - 툴 실행 결과)\\\\n\\\\n✔ tool_call_id는 AIMessage에서 요청했던 것과 동일해야 함.\\\\n✔ \\\\\"temperature\\\\\": 15, \\\\\"condition\\\\\": \\\\\"Sunny\\\\\"라는 결과를 반환.\\\\n\\\\n즉, 이 단계에서는 실제로 툴이 실행되며, API 호출, 데이터베이스 조회, 코드 실행 등의 작업을 수행하여 결과를 생성합니다.\\\\n\\\\n③ AIMessage (최종 응답 생성)\\\\n\\\\n툴이 반환한 결과를 바탕으로 LLM이 최종적으로 사용자에게 응답할 메시지를 생성합니다.\\\\n\\\\n🔹 예제 (AIMessage - 최종 응답)\\\\n\\\\n✔ LLM이 ToolMessage에서 받은 데이터를 바탕으로 자연어 응답을 생성.\\\\n✔ 툴을 통해 얻은 정보가 사용자에게 제공됨.\", \"score\": 0.6601948, \"raw_content\": null}, {\"url\": \"https://blog.leaphop.co.kr/blogs/90/MCP_%EC%84%9C%EB%B2%84_%EA%B5%AC%EC%B6%95_%EA%B0%80%EC%9D%B4%EB%93%9C\", \"title\": \"MCP 서버 구축 가이드 - TECH BLOG\", \"content\": \"Tool Calling(툴 콜링)은 LLM(GPT-4, Claude 등) Agent가 외부 함수(도구, API, DB, 파일, 플러그인 등)를 \\'동적으로\\' 호출(자동 매핑/체인 실행/결과\", \"score\": 0.531672, \"raw_content\": null}, {\"url\": \"https://uracle.blog/2025/03/28/agent%EC%9D%98-%EA%B8%B0%EB%B0%98%EC%9D%B4-%EB%90%98%EB%8A%94-llm-tool-calling/\", \"title\": \"Agent의 기반이 되는 LLM Tool Calling: ① 개념 알기 - 유라클 블로그\", \"content\": \"AI 에이전트가 단순한 챗봇과 다른 점은 도구 호출(Tool Calling) 능력입니다. 도구 호출은 LLM이 외부 API를 호출하거나, 특정 함수를 실행하거나, 다른\", \"score\": 0.493336, \"raw_content\": null}, {\"url\": \"https://aiandgamedev.com/ai/assistant-api-function-calling/\", \"title\": \"Assistants API \\'함수 호출(Function Calling)\\' 도구를 활용한 최저가 ...\", \"content\": \"OpenAI의 gpt-4-1106-preview 모델을 사용하여, \\'함수 호출\\' 기능을 포함하는 Assistant를 생성합니다. 이 Assistant는 사용자로부터 최저가와 환율 정보\", \"score\": 0.22589478, \"raw_content\": null}, {\"url\": \"https://meetcody.ai/ko/blog/2023%EB%85%84-%EA%B0%80%EC%9E%A5-%ED%81%B0-ai-%EB%8F%84%EA%B5%AC-%EB%B0%8F-%EB%AA%A8%EB%8D%B8-%EC%97%85%EB%8D%B0%EC%9D%B4%ED%8A%B8-20%EA%B0%80%EC%A7%80-with-features/\", \"title\": \"2023년 가장 큰 AI 도구 및 모델 업데이트 20가지 [With Features] - Cody\", \"content\": \"GPT-4는 고급 이미지 및 음성 해설 기능을 갖추고 있어 다양한 혁신과 활용 사례를 실현합니다. ChatGPT-4의 생성 AI는 ChatGPT-3 버전의 500배에\", \"score\": 0.20779322, \"raw_content\": null}, {\"url\": \"https://devocean.sk.com/blog/techBoardDetail.do?ID=167407&boardType=techBlog\", \"title\": \"Function Calling: LLM이 외부 세계와 소통하는 방법 (ft. Qwen, llama ...\", \"content\": \"Function Calling은 LLM이 자연어 요청을 이해하고 적합한 외부 API를 호출해 실시간 정보를 가져오는 기술로, 사용자가 요청한 정보를 보다 정확하고\", \"score\": 0.08120605, \"raw_content\": null}], \"response_time\": 3.58}', name='tavily_search', tool_call_id='37ba0fa2-66d5-4d38-b76d-5cbf54ccc37b')]\n",
            "====agent response====\n",
            "content='' additional_kwargs={'function_call': {'name': 'tavily_search', 'arguments': '{\"search_depth\": \"advanced\", \"query\": \"LLM tool calling \\\\uc0ac\\\\uc6a9\\\\ubc95\"}'}} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'models/gemini-2.5-flash-preview-05-20', 'safety_ratings': []} id='run-fb98e4fb-efd4-4996-9cf1-01fee480c063-0' tool_calls=[{'name': 'tavily_search', 'args': {'search_depth': 'advanced', 'query': 'LLM tool calling 사용법'}, 'id': '6a512e38-0f54-428a-bdb5-0b3d1cd36705', 'type': 'tool_call'}] usage_metadata={'input_tokens': 3633, 'output_tokens': 29, 'total_tokens': 4122, 'input_token_details': {'cache_read': 0}}\n",
            "====tool_calls====\n",
            "[{'name': 'tavily_search', 'args': {'search_depth': 'advanced', 'query': 'LLM tool calling 사용법'}, 'id': '6a512e38-0f54-428a-bdb5-0b3d1cd36705', 'type': 'tool_call'}]\n",
            "\n",
            "====call_agent====\n",
            "Agent에 대한 입력 메시지: [HumanMessage(content='AI 모델의 \"tool calling\"에 대한 기본 개념, 작동 원리, 주요 이점, 그리고 가장 일반적인 활용 분야 및 관련 프레임워크(예: OpenAI Function Calling, LangChain Tools)에 대한 정보를 광범위하게 검색하여 최소 10개 이상의 웹페이지에서 정보를 수집하고, 각 웹페이지의 전체 내용을 추출하여 \"tool calling\"의 다양한 측면을 대표할 수 있는 5가지 이상의 명확하고 독립적인 선택지(또는 활용 사례/방법)를 분류할 수 있는 충분한 정보를 확보합니다. 특히, \"AI 모델 tool calling 개념 및 활용 사례\", \"LLM tool calling 사용법\", \"OpenAI Function Calling 예시\", \"LangChain Tools 활용\" 등의 검색 쿼리를 사용하여 다양한 관점의 정보를 수집합니다.', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'function_call': {'name': 'tavily_search', 'arguments': '{\"search_depth\": \"advanced\", \"query\": \"AI \\\\ubaa8\\\\ub378 tool calling \\\\uac1c\\\\ub150 \\\\ubc0f \\\\ud65c\\\\uc6a9 \\\\uc0ac\\\\ub840\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'models/gemini-2.5-flash-preview-05-20', 'safety_ratings': []}, id='run-d1ac2b25-faf2-46e3-bf26-008fc6415994-0', tool_calls=[{'name': 'tavily_search', 'args': {'search_depth': 'advanced', 'query': 'AI 모델 tool calling 개념 및 활용 사례'}, 'id': '37ba0fa2-66d5-4d38-b76d-5cbf54ccc37b', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1477, 'output_tokens': 31, 'total_tokens': 1824, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='{\"query\": \"AI 모델 tool calling 개념 및 활용 사례\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://dytis.tistory.com/98\", \"title\": \"LangChain을 활용한 Tool Calling # 3 - DEV.DY - 티스토리\", \"content\": \"Tool Calling의 개념 ... Tool Calling은 말 그대로 특정 작업을 수행할 수 있는 툴을 호출하는 것을 의미합니다. 예를 들어, AI가 날씨 정보를 제공해야 할\", \"score\": 0.8138313, \"raw_content\": null}, {\"url\": \"https://digitalbourgeois.tistory.com/885\", \"title\": \"Spring AI의 새로운 도구 호출 기능: AI와 API의 강력한 연동 방법!\", \"content\": \"Tool Calling(도구 호출)은 AI 모델이 특정 API나 도구를 직접 호출하여 데이터를 가져오거나 연산을 수행할 수 있도록 지원하는 기능입니다. ✓ 이전 방식\", \"score\": 0.8029425, \"raw_content\": null}, {\"url\": \"https://dytis.tistory.com/95\", \"title\": \"LLM 어플리케이션에서의 Tool Calling: AI가 더 똑똑해지는 방법\", \"content\": \"OpenAI CookBook에서 소개하는 Tool calling의 실제 적용 사례는 쇼핑 어시스턴트, 고객 서비스 에이전트, 그리고 인터랙티브 예약 경험입니다. 쇼핑\", \"score\": 0.798643, \"raw_content\": null}, {\"url\": \"https://claremont.tistory.com/entry/%EC%83%9D%EC%84%B1%ED%98%95-AI-LLM%EC%9D%98-Tool-Calling%EB%8F%84%EA%B5%AC-%ED%98%B8%EC%B6%9C%EC%9D%B4%EB%9E%80\", \"title\": \"[생성형 AI] LLM의 Tool Calling(도구 호출)이란? - Go for IT - 티스토리\", \"content\": \"Tool Calling은 LLM이 외부 도구를 활용하여 보다 정확하고 신뢰할 수 있는 응답을 생성하는 기술이다. 이를 통해 최신 정보를 반영하고, 연산을 수행하며\", \"score\": 0.685971, \"raw_content\": null}, {\"url\": \"https://velog.io/@byu0hyun/AIMessage-ToolMessage-Tool-Calling-%ED%9D%90%EB%A6%84-%EC%9D%B4%ED%95%B4\", \"title\": \"AIMessage, ToolMessage, Tool Calling 흐름 이해 - velog\", \"content\": \"AIMessage, ToolMessage, Tool Calling 흐름 이해\\\\n\\\\nAIMessage, ToolMessage, Tool Calling 완벽 이해: AIMessage → ToolMessage → AIMessage 흐름\\\\n\\\\nAI 기반의 챗봇이나 자동화 시스템을 설계할 때, 단순히 모델이 답변을 생성하는 것이 아니라 외부 API, 데이터베이스, 코드 실행 등의 툴(Tool)을 호출해야 하는 경우가 많습니다.\\\\n이때 Tool Calling(툴 호출) 개념이 사용되며, 대표적으로 OpenAI의 Function Calling이나 LangChain의 Tool 기능이 있습니다.\\\\n\\\\n오늘은 Tool Calling의 핵심 흐름인 AIMessage → ToolMessage → AIMessage 구조를 이해하고, tool_calls 필드가 왜 중요한지 살펴보겠습니다.\\\\n\\\\n1. AIMessage → ToolMessage → AIMessage 흐름이란? [...] Tool Calling 과정에서 메시지는 다음과 같은 흐름을 따릅니다.\\\\n\\\\n① AIMessage (툴 호출 요청)\\\\n\\\\n사용자의 질문을 받은 LLM이 자체적으로 답변을 생성하지 않고, 외부 툴을 호출해야 한다고 판단하면 tool_calls 필드를 포함한 메시지를 생성합니다.\\\\n이때 중요한 점은 LLM이 직접 툴을 실행하는 것이 아니라, 툴을 호출하는 요청만 만든다는 것입니다.\\\\n\\\\n🔹 예제 (AIMessage - Tool 호출 요청)\\\\n\\\\n✔ \\\\\"get_weather\\\\\"라는 툴을 호출해야 함을 나타냄.\\\\n✔ \\\\\"location\\\\\": \\\\\"Seoul\\\\\" 값을 툴에 전달하도록 요청함.\\\\n✔ LLM은 툴을 직접 실행하지 않고, 툴을 호출하는 요청만 생성.\\\\n\\\\n즉, tool_calls이 포함된 AIMessage는 반드시 툴을 실행해야 하며, 툴이 실행되지 않으면 LLM은 후속 응답을 생성할 수 없습니다.\\\\n\\\\n② ToolMessage (툴 실행 및 결과 반환) [...] AIMessage에서 툴을 호출했으므로, 실제 툴이 실행되고 결과를 반환해야 합니다.\\\\n이 역할을 하는 것이 ToolMessage이며, 툴의 실행 결과를 담고 있습니다.\\\\n\\\\n🔹 예제 (ToolMessage - 툴 실행 결과)\\\\n\\\\n✔ tool_call_id는 AIMessage에서 요청했던 것과 동일해야 함.\\\\n✔ \\\\\"temperature\\\\\": 15, \\\\\"condition\\\\\": \\\\\"Sunny\\\\\"라는 결과를 반환.\\\\n\\\\n즉, 이 단계에서는 실제로 툴이 실행되며, API 호출, 데이터베이스 조회, 코드 실행 등의 작업을 수행하여 결과를 생성합니다.\\\\n\\\\n③ AIMessage (최종 응답 생성)\\\\n\\\\n툴이 반환한 결과를 바탕으로 LLM이 최종적으로 사용자에게 응답할 메시지를 생성합니다.\\\\n\\\\n🔹 예제 (AIMessage - 최종 응답)\\\\n\\\\n✔ LLM이 ToolMessage에서 받은 데이터를 바탕으로 자연어 응답을 생성.\\\\n✔ 툴을 통해 얻은 정보가 사용자에게 제공됨.\", \"score\": 0.6601948, \"raw_content\": null}, {\"url\": \"https://blog.leaphop.co.kr/blogs/90/MCP_%EC%84%9C%EB%B2%84_%EA%B5%AC%EC%B6%95_%EA%B0%80%EC%9D%B4%EB%93%9C\", \"title\": \"MCP 서버 구축 가이드 - TECH BLOG\", \"content\": \"Tool Calling(툴 콜링)은 LLM(GPT-4, Claude 등) Agent가 외부 함수(도구, API, DB, 파일, 플러그인 등)를 \\'동적으로\\' 호출(자동 매핑/체인 실행/결과\", \"score\": 0.531672, \"raw_content\": null}, {\"url\": \"https://uracle.blog/2025/03/28/agent%EC%9D%98-%EA%B8%B0%EB%B0%98%EC%9D%B4-%EB%90%98%EB%8A%94-llm-tool-calling/\", \"title\": \"Agent의 기반이 되는 LLM Tool Calling: ① 개념 알기 - 유라클 블로그\", \"content\": \"AI 에이전트가 단순한 챗봇과 다른 점은 도구 호출(Tool Calling) 능력입니다. 도구 호출은 LLM이 외부 API를 호출하거나, 특정 함수를 실행하거나, 다른\", \"score\": 0.493336, \"raw_content\": null}, {\"url\": \"https://aiandgamedev.com/ai/assistant-api-function-calling/\", \"title\": \"Assistants API \\'함수 호출(Function Calling)\\' 도구를 활용한 최저가 ...\", \"content\": \"OpenAI의 gpt-4-1106-preview 모델을 사용하여, \\'함수 호출\\' 기능을 포함하는 Assistant를 생성합니다. 이 Assistant는 사용자로부터 최저가와 환율 정보\", \"score\": 0.22589478, \"raw_content\": null}, {\"url\": \"https://meetcody.ai/ko/blog/2023%EB%85%84-%EA%B0%80%EC%9E%A5-%ED%81%B0-ai-%EB%8F%84%EA%B5%AC-%EB%B0%8F-%EB%AA%A8%EB%8D%B8-%EC%97%85%EB%8D%B0%EC%9D%B4%ED%8A%B8-20%EA%B0%80%EC%A7%80-with-features/\", \"title\": \"2023년 가장 큰 AI 도구 및 모델 업데이트 20가지 [With Features] - Cody\", \"content\": \"GPT-4는 고급 이미지 및 음성 해설 기능을 갖추고 있어 다양한 혁신과 활용 사례를 실현합니다. ChatGPT-4의 생성 AI는 ChatGPT-3 버전의 500배에\", \"score\": 0.20779322, \"raw_content\": null}, {\"url\": \"https://devocean.sk.com/blog/techBoardDetail.do?ID=167407&boardType=techBlog\", \"title\": \"Function Calling: LLM이 외부 세계와 소통하는 방법 (ft. Qwen, llama ...\", \"content\": \"Function Calling은 LLM이 자연어 요청을 이해하고 적합한 외부 API를 호출해 실시간 정보를 가져오는 기술로, 사용자가 요청한 정보를 보다 정확하고\", \"score\": 0.08120605, \"raw_content\": null}], \"response_time\": 3.58}', name='tavily_search', tool_call_id='37ba0fa2-66d5-4d38-b76d-5cbf54ccc37b'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'tavily_search', 'arguments': '{\"search_depth\": \"advanced\", \"query\": \"LLM tool calling \\\\uc0ac\\\\uc6a9\\\\ubc95\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'models/gemini-2.5-flash-preview-05-20', 'safety_ratings': []}, id='run-fb98e4fb-efd4-4996-9cf1-01fee480c063-0', tool_calls=[{'name': 'tavily_search', 'args': {'search_depth': 'advanced', 'query': 'LLM tool calling 사용법'}, 'id': '6a512e38-0f54-428a-bdb5-0b3d1cd36705', 'type': 'tool_call'}], usage_metadata={'input_tokens': 3633, 'output_tokens': 29, 'total_tokens': 4122, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='{\"query\": \"LLM tool calling 사용법\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://medium.com/@developer.yasir.pk/tool-calling-for-llms-a-detailed-tutorial-a2b4d78633e2\", \"title\": \"Tool Calling for LLMs: A Detailed Tutorial | by Explore With Yasir\", \"content\": \"Tool calling allows an LLM to interact with external tools during conversation generation. This means the LLM can access information or perform actions beyond its own knowledge base. Tools can be functions written by developers, APIs for external services, or any resource the LLM can interact with.\\\\n\\\\nHow to Achieve Tool Calling\\\\n\\\\nHere’s a breakdown of the steps involved:\\\\n\\\\nDefine Your Tools:\\\\n\\\\nPrepare the Conversation:\\\\n\\\\nPass Tools to the LLM:\\\\n\\\\nInterpret LLM Output:\\\\n\\\\nExecute Tool Calls: [...] The code then demonstrates capturing the LLM’s tool call, calling the function with its arguments, and adding the result (a dummy value of 22.0) to the conversation history. Finally, it shows how to continue the conversation by feeding the updated history back to the LLM.\\\\n\\\\nBenefits of Tool Calling\\\\n\\\\nTool calling allows LLMs to:\\\\n\\\\nThis makes LLMs more versatile and powerful for various applications.\\\\n\\\\nAdditional Notes [...] Incorporate Tool Results:\\\\n\\\\nContinue Conversation:\\\\n\\\\nThe Complete Example\\\\n\\\\nThe provided code demonstrates using tool calling with a weather bot. The bot uses functions get_current_temperature and get_current_wind_speed to retrieve (simulated) weather data. The LLM infers the user wants the temperature in Celsius and suggests calling get_current_temperature.\", \"score\": 0.8332299, \"raw_content\": null}, {\"url\": \"https://velog.io/@nylonmask/chat-completion-api-%EC%97%90%EC%84%9C%EC%9D%98-tool-calls\", \"title\": \"chat completion api 의 function call - velog\", \"content\": \"chat completion api 의 function call\\\\n\\\\nFunction calling (tool calls)\\\\n\\\\nhttps://platform.openai.com/docs/guides/function-calling\\\\n\\\\n결론 부터 말하면 function calling은 llm이 사용자의 질의를 읽고, 로컬 코드에 구현된 함수 중에 어떤 걸 호출할지 선택하는 기능이다.\\\\n\\\\nfunction call의 lifecycle\\\\n\\\\n\\\\n\\\\n여기서 주의할 점은, llm이 해당 함수를 직접 실행하는 것이 아니다. llm은 단지 3번째 단계에서 해당 function을 실행하는데 필요한 arguments를 생성해서 사용자에게 넘겨줄 뿐이다. 사용자는 이 파라미터를 받아서 알아서 쓰면 된다.\\\\n\\\\nfunction calling 사용법 [...] tool calls는 여러 개의 함수를 정의해서 llm에게 알려주면, llm이 사용자의 질의를 보고 어떤 함수를 써야할지 판단하여 호출할 함수 이름 필요한 파라미터 값을 준다. 그럼 agent는 해당 결과를 기반으로 실제 함수를 호출한다.\\\\n\\\\n추가적인 팁\\\\n\\\\n1. 구조화된 출력 사용\\\\n\\\\n복잡한 스키마를 사용할 때 모델이 매개변수를 놓치거나 매개변수의 유형을 잘못 지정할 때가 가끔 있는데, \\\\\"구조화된 출력\\\\\" 기능을 사용하면 함수 호출에 대한 모델 출력이 제공된 스키마와 정확히 일치하도록 보장한다.\\\\nstrict: true. 옵션만 주면 된다. 그냥 켜두는 걸 권장한다.\\\\n\\\\n구조화된 출력을 활성화하면 OpenAI API는 첫 번째 요청 시 제공된 스키마를 사전 처리한 다음 이 아티팩트를 사용하여 모델을 스키마에 맞게 제한한다.\\\\n\\\\n모델은 몇 가지 상황을 제외하고 항상 정확한 스키마를 따른다.\\\\n\\\\n2. tool_choice를 사용해 함수 호출 동작 구성 [...] 아래 예시는 사용자의 배달 주문을 도울 수 있는 대화형 assistant의 예시다. 사용자는 ai기반의 assistant와 채팅할 수 있다. 이 assistant를 유용하게 만들기 위해 주문을 조회하고 사용자 주문에 대한 실제 데이터로 답변할 수 있는 기능을 제공하고자 한다.\\\\n\\\\n1단계: 모델이 호출할 수 있는 코드 베이스의 함수를 선택한다.\\\\n\\\\n코드상에 구현해둔 함수를 선택한다. 이 함수에 대한 정보를 llm에 알려주면, 함수를 실행하기 위해 필요한 arguments를 llm이 생성할 것이다. 배송 날짜를 가져오는 get_delivery_date() 함수를 구현하고 선택한다고 가정하자.\\\\n\\\\n2단계: 모델에 함수를 설명하여 호출 방법을 알려준다.\\\\n\\\\n함수를 선택했으면 모델에 함수를 설명할 \\\\\"함수 정의\\\\\"를 만든다. 이 정의에는 함수가 수행하는 작업(그리고 잠재적으로 언제 호출해야 하는지)과 함수를 호출하는 데 필요한 매개변수를 모두 포함한다.\", \"score\": 0.79022324, \"raw_content\": null}, {\"url\": \"https://dytis.tistory.com/98\", \"title\": \"LangChain을 활용한 Tool Calling # 3 - DEV.DY - 티스토리\", \"content\": \"Tool Calling의 개념\\\\n\\\\nTool Calling은 말 그대로 특정 작업을 수행할 수 있는 툴을 호출하는 것을 의미합니다. 예를 들어, AI가 날씨 정보를 제공해야 할 때, AI가 직접 날씨 API를 호출하여 사용자가 원하는 정보를 전달하는 방식입니다. LangChain을 통해 LLM(Large Language Model)이 직접 툴을 호출하고, 그 결과를 사용하여 사용자에게 답변을 제공할 수 있습니다. Tool Calling에 대한 추가적인 정보는 블로그의 이전 포스트를 참고해주세요.\\\\n\\\\nLLM 어플리케이션에서의 Tool Calling: AI가 더 똑똑해지는 방법\\\\n\\\\nLLM(대형 언어 모델) 어플리케이션이 갈수록 더 많은 일들을 할 수 있게 되면서, \\\\\"Tool calling\\\\\" 기능은 그중에서도 가장 주목할 만한 혁신 중 하나로 자리 잡고 있습니다. 이 기능은 AI가 외부의 도구\\\\n\\\\ndytis.tistory.com [...] Tool calls\\\\n\\\\nLLM 응답에 도구 호출이 포함되는 경우 도구 호출 개체 목록인 .tool_calls 속성으로 해당 메시지나 메시지 청크에 첨부됩니다. chat models는 여러 도구를 동시에 호출할 수 있습니다. ToolCall은 a tool name, dict of argument values, and (optionally) an identifier를 포함하는 typed dict입니다. 도구 호출이 없는 메시지는 이 속성에 대해 기본적으로 빈 목록이 됩니다.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nParsing\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nHow to: pass\\xa0tool\\xa0outputs\\xa0to\\xa0chat\\xa0models\\\\n\\\\nHow to pass tool outputs to chat models | 🦜️🔗 LangChain\\\\n\\\\nThis guide assumes familiarity with the following concepts:\\\\n\\\\npython.langchain.com [...] 런타임에만 알려진 도구에 값을 바인딩해야 할 수도 있습니다. 예를 들어, 도구 로직은 요청을 한 사용자의 ID를 사용해야 할 수도 있습니다. 대부분의 경우, 이러한 값은 LLM에서 제어해서는 안 됩니다. 사실, LLM이 사용자 ID를 제어하도록 허용하면 보안 위험이 발생할 수 있습니다. 대신 LLM은 LLM이 제어하도록 의도된 도구의 parameters만 제어해야 하며, 다른 parameters(예: 사용자 ID)는 애플리케이션 논리에 의해 고정되어야 합니다. 이 방법 가이드에서는 모델이 특정 도구 arguments를 생성하여 런타임에 직접 주입하는 것을 방지하는 방법을 보여줍니다.\\\\n\\\\n\\\\n\\\\n모델에서 arguments 숨기기\\\\n\\\\n이러한 도구의 입력 스키마를 살펴보면 user_id가 여전히 나열되어 있는 것을 볼 수 있습니다.\\\\n\\\\n\\\\n\\\\n하지만 도구 호출을 위해 모델에 전달되는 도구 호출 스키마를 살펴보면 user_id가 제거되었습니다.\", \"score\": 0.780947, \"raw_content\": null}, {\"url\": \"https://medium.com/@craftsangjae/llm-agent-%EA%B0%9C%EB%B0%9C%ED%95%98%EA%B8%B0-2-tool-calling-e87e664f23df\", \"title\": \"LLM Agent 개발하기 (2) Tool Calling. 들어가기 앞서 - Medium\", \"content\": \"LLM은 기본적으로 Text을 받아, Text를 반환하는 함수입니다. LLM은 직접 함수를 실행시킬 수 있는 기능은 없습니다. 하지만 LLM은 어떤 함수를 어떻게 호출해야 하는지를추론할 수 있습니다.\\\\n\\\\nLLM이 위 함수를 활용해서,아래 문장을 통해 어떤 함수를 호출하면 될지를 추론(Reasoning)하도록 만들면 됩니다.\\\\n\\\\nLangchain에서 제공하는 Tool 데코레이터\\\\n\\\\nLLM이 저런 함수를 다룰 수 있도록 Langchain Tool 이 존재합니다. LLM에게 먼저 함수에 대해 구체적으로 설명해주어야 합니다. 이를 위해 아래와 같이 함수에 Docstring을 추가하고, @tool(parse_docstring=True) 을 추가합니다. [...] LLM 모델은 과거 데이터에 기반해있기 때문에, 현재의 정보를 요청한다면 위처럼 거부합니다. 그렇기 때문에 LLM이 현재 주가 정보를 확보할 수 있는 방법이 필요합니다.\\\\n\\\\n외부도구 : Python을 통한 주식 가격 조회\\\\n\\\\n파이썬 패키지 중 하나인 `yfinance`는 편리하게 금융 정보를 조회할 수 있습니다. yfinance를 활용해서 주식 정보를 조회해 보도록 하겠습니다.\\\\n\\\\n이렇게 작성한 함수를 통해, 우리는 원하는 정보들을 쉽게 가져올 수 있습니다.\\\\n\\\\nLLM이 위 함수를 이용할 수 있다면, 우리에게 원하는 답변을 말할 수 있지 않을까요? LLM에게 어떤 도구가 있는지를 알려주어서 해당 도구를 사용할 수 있도록 만드는 것이 바로 `Tool Calling` 입니다.\\\\n\\\\nTool Calling: LLM이 Action을 수행하는 방법 [...] Sign up\\\\n\\\\nSign in\\\\n\\\\nSign up\\\\n\\\\nSign in\\\\n\\\\nLLM Agent 개발하기 (2) Tool Calling\\\\n\\\\n--\\\\n\\\\nShare\\\\n\\\\n들어가기 앞서\\\\n\\\\n이 시리즈의 두 번째 글로, LLM에게 외부의 도구들을 연동하는 방법인 Tool Calling을 다뤄보도록 하겠습니다.\\\\n\\\\nLLM이 할 수 없는 일들이 많습니다. 예를 들면, 지금 날씨가 어떤지 묻거나, 오늘 있었던 사건사고를 물으면, 이에 대한 정보가 없는 LLM은 적절한 대답을 할 수 없습니다. 하지만, 외부의 도구를 적절히 제공해준다면, LLM은 처리해낼 수 있습니다. 이렇게 LLM에게 도구를 제공하는 방법이 바로 “Tool Calling”입니다.\\\\n\\\\nLLM이 풀지 못하는 문제: 지금 엔비디아 주가 얼마야?\\\\n\\\\nLLM은 학습한 시점의 기억만을 가지고 있습니다. LLM에게 오늘의 날짜를 물어보면, 그들은 현재 날짜가 아닌, 그들 기억 속의 날짜를 답변합니다. 그렇기 때문에 아래와 같이 실행하면 LLM은 아래와 같이 답변합니다.\", \"score\": 0.76194656, \"raw_content\": null}, {\"url\": \"https://uracle.blog/2025/03/28/agent%EC%9D%98-%EA%B8%B0%EB%B0%98%EC%9D%B4-%EB%90%98%EB%8A%94-llm-tool-calling/\", \"title\": \"Agent의 기반이 되는 LLM Tool Calling: ① 개념 알기 - 유라클 블로그\", \"content\": \"LLM Tool Calling에서 도구(Tool)이란? LLM이 외부 세계와 상호작용하기 위해 사용하는 인터페이스입니다. 이는 특정 작업을 수행하는 함수(예: 날씨 정보\", \"score\": 0.7576693, \"raw_content\": null}, {\"url\": \"https://dytis.tistory.com/95\", \"title\": \"LLM 어플리케이션에서의 Tool Calling: AI가 더 똑똑해지는 방법\", \"content\": \"1) Tool creation ... Tool을 생성하는 데 권장되는 방법은 @tool 데코레이터를 사용하는 것입니다. from langchain_core.tools import tool @tool\", \"score\": 0.7548612, \"raw_content\": null}, {\"url\": \"https://usingsystem.tistory.com/566\", \"title\": \"[AI] LangChain - Tool Calling 사용법 - 발자취 - 티스토리\", \"content\": \"LLM이 Tool Calling을 통해 도구를 호출했을 때 이름으로 나옵니다. 어떤 툴을 호출했는지 이름을 기준으로 분기해서 실행 시킬 수 있습니다. tool_calls\", \"score\": 0.68064564, \"raw_content\": null}, {\"url\": \"https://www.youtube.com/watch?v=zCwuAlpQKTM&pp=0gcJCdgAo7VqN5tD\", \"title\": \"Tool Calling with LangChain - YouTube\", \"content\": \"Comments · LLM Function Calling - AI Tools Deep Dive · Fully local tool calling with Ollama · Function Calling with LLM using LangChain + Ollama.\", \"score\": 0.5914643, \"raw_content\": null}, {\"url\": \"https://wikidocs.net/261566\", \"title\": \"Part 4. LangChain Agent - 도구 호출 (Tool Calling) - 위키독스\", \"content\": \"도구 호출(Tool Calling)은 LangChain에서 언어 모델이 외부 도구나 API를 사용할 수 있게 해주는 중요한 기능입니다. 이를 통해 AI 모델은 실시간 정보 검색, 계산,\", \"score\": 0.528169, \"raw_content\": null}, {\"url\": \"https://devocean.sk.com/blog/techBoardDetail.do?ID=167407&boardType=techBlog\", \"title\": \"Function Calling: LLM이 외부 세계와 소통하는 방법 (ft. Qwen, llama ...\", \"content\": \"5.2.3 TOOL의 정의. 주식 정보를 가져오는 함수 get_kospi_stock_info 에 대해 JSON 스키마 형식으로 함수를 정의합니다. TOOLS = [\", \"score\": 0.5172057, \"raw_content\": null}], \"response_time\": 3.42}', name='tavily_search', tool_call_id='6a512e38-0f54-428a-bdb5-0b3d1cd36705')]\n",
            "====agent response====\n",
            "content='' additional_kwargs={'function_call': {'name': 'tavily_extract', 'arguments': '{\"urls\": [\"https://dytis.tistory.com/98\", \"https://digitalbourgeois.tistory.com/885\", \"https://dytis.tistory.com/95\", \"https://claremont.tistory.com/entry/%EC%83%9D%EC%84%B1%ED%98%95-AI-LLM%EC%9D%98-Tool-Calling%EB%8F%84%EA%B5%AC-%ED%98%B8%EC%B6%9C%EC%9D%B4%EB%9E%80\", \"https://velog.io/@byu0hyun/AIMessage-ToolMessage-Tool-Calling-%ED%9D%90%EB%A6%84-%EC%9D%B4%ED%95%B4\", \"https://uracle.blog/2025/03/28/agent%EC%9D%98-%EA%B8%B0%EB%B0%98%EC%9D%B4-%EB%90%98%EB%8A%94-llm-tool-calling/\", \"https://aiandgamedev.com/ai/assistant-api-function-calling/\", \"https://medium.com/@developer.yasir.pk/tool-calling-for-llms-a-detailed-tutorial-a2b4d78633e2\", \"https://velog.io/@nylonmask/chat-completion-api-%EC%97%90%EC%84%A4%EC%9D%98-tool-calls\", \"https://medium.com/@craftsangjae/llm-agent-%EA%B0%9C%EB%B0%9C%ED%95%98%EA%B8%B0-2-tool-calling-e87e664f23df\"]}'}} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'models/gemini-2.5-flash-preview-05-20', 'safety_ratings': []} id='run-edec9e60-7133-4349-8680-ea5d1b101477-0' tool_calls=[{'name': 'tavily_extract', 'args': {'urls': ['https://dytis.tistory.com/98', 'https://digitalbourgeois.tistory.com/885', 'https://dytis.tistory.com/95', 'https://claremont.tistory.com/entry/%EC%83%9D%EC%84%B1%ED%98%95-AI-LLM%EC%9D%98-Tool-Calling%EB%8F%84%EA%B5%AC-%ED%98%B8%EC%B6%9C%EC%9D%B4%EB%9E%80', 'https://velog.io/@byu0hyun/AIMessage-ToolMessage-Tool-Calling-%ED%9D%90%EB%A6%84-%EC%9D%B4%ED%95%B4', 'https://uracle.blog/2025/03/28/agent%EC%9D%98-%EA%B8%B0%EB%B0%98%EC%9D%B4-%EB%90%98%EB%8A%94-llm-tool-calling/', 'https://aiandgamedev.com/ai/assistant-api-function-calling/', 'https://medium.com/@developer.yasir.pk/tool-calling-for-llms-a-detailed-tutorial-a2b4d78633e2', 'https://velog.io/@nylonmask/chat-completion-api-%EC%97%90%EC%84%A4%EC%9D%98-tool-calls', 'https://medium.com/@craftsangjae/llm-agent-%EA%B0%9C%EB%B0%9C%ED%95%98%EA%B8%B0-2-tool-calling-e87e664f23df']}, 'id': 'fe7e93c3-542f-4a02-a356-825604f7fa93', 'type': 'tool_call'}] usage_metadata={'input_tokens': 6982, 'output_tokens': 468, 'total_tokens': 9264, 'input_token_details': {'cache_read': 0}}\n",
            "====tool_calls====\n",
            "[{'name': 'tavily_extract', 'args': {'urls': ['https://dytis.tistory.com/98', 'https://digitalbourgeois.tistory.com/885', 'https://dytis.tistory.com/95', 'https://claremont.tistory.com/entry/%EC%83%9D%EC%84%B1%ED%98%95-AI-LLM%EC%9D%98-Tool-Calling%EB%8F%84%EA%B5%AC-%ED%98%B8%EC%B6%9C%EC%9D%B4%EB%9E%80', 'https://velog.io/@byu0hyun/AIMessage-ToolMessage-Tool-Calling-%ED%9D%90%EB%A6%84-%EC%9D%B4%ED%95%B4', 'https://uracle.blog/2025/03/28/agent%EC%9D%98-%EA%B8%B0%EB%B0%98%EC%9D%B4-%EB%90%98%EB%8A%94-llm-tool-calling/', 'https://aiandgamedev.com/ai/assistant-api-function-calling/', 'https://medium.com/@developer.yasir.pk/tool-calling-for-llms-a-detailed-tutorial-a2b4d78633e2', 'https://velog.io/@nylonmask/chat-completion-api-%EC%97%90%EC%84%A4%EC%9D%98-tool-calls', 'https://medium.com/@craftsangjae/llm-agent-%EA%B0%9C%EB%B0%9C%ED%95%98%EA%B8%B0-2-tool-calling-e87e664f23df']}, 'id': 'fe7e93c3-542f-4a02-a356-825604f7fa93', 'type': 'tool_call'}]\n",
            "\n",
            "====call_agent====\n",
            "Agent에 대한 입력 메시지: [HumanMessage(content='AI 모델의 \"tool calling\"에 대한 기본 개념, 작동 원리, 주요 이점, 그리고 가장 일반적인 활용 분야 및 관련 프레임워크(예: OpenAI Function Calling, LangChain Tools)에 대한 정보를 광범위하게 검색하여 최소 10개 이상의 웹페이지에서 정보를 수집하고, 각 웹페이지의 전체 내용을 추출하여 \"tool calling\"의 다양한 측면을 대표할 수 있는 5가지 이상의 명확하고 독립적인 선택지(또는 활용 사례/방법)를 분류할 수 있는 충분한 정보를 확보합니다. 특히, \"AI 모델 tool calling 개념 및 활용 사례\", \"LLM tool calling 사용법\", \"OpenAI Function Calling 예시\", \"LangChain Tools 활용\" 등의 검색 쿼리를 사용하여 다양한 관점의 정보를 수집합니다.', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'function_call': {'name': 'tavily_search', 'arguments': '{\"search_depth\": \"advanced\", \"query\": \"AI \\\\ubaa8\\\\ub378 tool calling \\\\uac1c\\\\ub150 \\\\ubc0f \\\\ud65c\\\\uc6a9 \\\\uc0ac\\\\ub840\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'models/gemini-2.5-flash-preview-05-20', 'safety_ratings': []}, id='run-d1ac2b25-faf2-46e3-bf26-008fc6415994-0', tool_calls=[{'name': 'tavily_search', 'args': {'search_depth': 'advanced', 'query': 'AI 모델 tool calling 개념 및 활용 사례'}, 'id': '37ba0fa2-66d5-4d38-b76d-5cbf54ccc37b', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1477, 'output_tokens': 31, 'total_tokens': 1824, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='{\"query\": \"AI 모델 tool calling 개념 및 활용 사례\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://dytis.tistory.com/98\", \"title\": \"LangChain을 활용한 Tool Calling # 3 - DEV.DY - 티스토리\", \"content\": \"Tool Calling의 개념 ... Tool Calling은 말 그대로 특정 작업을 수행할 수 있는 툴을 호출하는 것을 의미합니다. 예를 들어, AI가 날씨 정보를 제공해야 할\", \"score\": 0.8138313, \"raw_content\": null}, {\"url\": \"https://digitalbourgeois.tistory.com/885\", \"title\": \"Spring AI의 새로운 도구 호출 기능: AI와 API의 강력한 연동 방법!\", \"content\": \"Tool Calling(도구 호출)은 AI 모델이 특정 API나 도구를 직접 호출하여 데이터를 가져오거나 연산을 수행할 수 있도록 지원하는 기능입니다. ✓ 이전 방식\", \"score\": 0.8029425, \"raw_content\": null}, {\"url\": \"https://dytis.tistory.com/95\", \"title\": \"LLM 어플리케이션에서의 Tool Calling: AI가 더 똑똑해지는 방법\", \"content\": \"OpenAI CookBook에서 소개하는 Tool calling의 실제 적용 사례는 쇼핑 어시스턴트, 고객 서비스 에이전트, 그리고 인터랙티브 예약 경험입니다. 쇼핑\", \"score\": 0.798643, \"raw_content\": null}, {\"url\": \"https://claremont.tistory.com/entry/%EC%83%9D%EC%84%B1%ED%98%95-AI-LLM%EC%9D%98-Tool-Calling%EB%8F%84%EA%B5%AC-%ED%98%B8%EC%B6%9C%EC%9D%B4%EB%9E%80\", \"title\": \"[생성형 AI] LLM의 Tool Calling(도구 호출)이란? - Go for IT - 티스토리\", \"content\": \"Tool Calling은 LLM이 외부 도구를 활용하여 보다 정확하고 신뢰할 수 있는 응답을 생성하는 기술이다. 이를 통해 최신 정보를 반영하고, 연산을 수행하며\", \"score\": 0.685971, \"raw_content\": null}, {\"url\": \"https://velog.io/@byu0hyun/AIMessage-ToolMessage-Tool-Calling-%ED%9D%90%EB%A6%84-%EC%9D%B4%ED%95%B4\", \"title\": \"AIMessage, ToolMessage, Tool Calling 흐름 이해 - velog\", \"content\": \"AIMessage, ToolMessage, Tool Calling 흐름 이해\\\\n\\\\nAIMessage, ToolMessage, Tool Calling 완벽 이해: AIMessage → ToolMessage → AIMessage 흐름\\\\n\\\\nAI 기반의 챗봇이나 자동화 시스템을 설계할 때, 단순히 모델이 답변을 생성하는 것이 아니라 외부 API, 데이터베이스, 코드 실행 등의 툴(Tool)을 호출해야 하는 경우가 많습니다.\\\\n이때 Tool Calling(툴 호출) 개념이 사용되며, 대표적으로 OpenAI의 Function Calling이나 LangChain의 Tool 기능이 있습니다.\\\\n\\\\n오늘은 Tool Calling의 핵심 흐름인 AIMessage → ToolMessage → AIMessage 구조를 이해하고, tool_calls 필드가 왜 중요한지 살펴보겠습니다.\\\\n\\\\n1. AIMessage → ToolMessage → AIMessage 흐름이란? [...] Tool Calling 과정에서 메시지는 다음과 같은 흐름을 따릅니다.\\\\n\\\\n① AIMessage (툴 호출 요청)\\\\n\\\\n사용자의 질문을 받은 LLM이 자체적으로 답변을 생성하지 않고, 외부 툴을 호출해야 한다고 판단하면 tool_calls 필드를 포함한 메시지를 생성합니다.\\\\n이때 중요한 점은 LLM이 직접 툴을 실행하는 것이 아니라, 툴을 호출하는 요청만 만든다는 것입니다.\\\\n\\\\n🔹 예제 (AIMessage - Tool 호출 요청)\\\\n\\\\n✔ \\\\\"get_weather\\\\\"라는 툴을 호출해야 함을 나타냄.\\\\n✔ \\\\\"location\\\\\": \\\\\"Seoul\\\\\" 값을 툴에 전달하도록 요청함.\\\\n✔ LLM은 툴을 직접 실행하지 않고, 툴을 호출하는 요청만 생성.\\\\n\\\\n즉, tool_calls이 포함된 AIMessage는 반드시 툴을 실행해야 하며, 툴이 실행되지 않으면 LLM은 후속 응답을 생성할 수 없습니다.\\\\n\\\\n② ToolMessage (툴 실행 및 결과 반환) [...] AIMessage에서 툴을 호출했으므로, 실제 툴이 실행되고 결과를 반환해야 합니다.\\\\n이 역할을 하는 것이 ToolMessage이며, 툴의 실행 결과를 담고 있습니다.\\\\n\\\\n🔹 예제 (ToolMessage - 툴 실행 결과)\\\\n\\\\n✔ tool_call_id는 AIMessage에서 요청했던 것과 동일해야 함.\\\\n✔ \\\\\"temperature\\\\\": 15, \\\\\"condition\\\\\": \\\\\"Sunny\\\\\"라는 결과를 반환.\\\\n\\\\n즉, 이 단계에서는 실제로 툴이 실행되며, API 호출, 데이터베이스 조회, 코드 실행 등의 작업을 수행하여 결과를 생성합니다.\\\\n\\\\n③ AIMessage (최종 응답 생성)\\\\n\\\\n툴이 반환한 결과를 바탕으로 LLM이 최종적으로 사용자에게 응답할 메시지를 생성합니다.\\\\n\\\\n🔹 예제 (AIMessage - 최종 응답)\\\\n\\\\n✔ LLM이 ToolMessage에서 받은 데이터를 바탕으로 자연어 응답을 생성.\\\\n✔ 툴을 통해 얻은 정보가 사용자에게 제공됨.\", \"score\": 0.6601948, \"raw_content\": null}, {\"url\": \"https://blog.leaphop.co.kr/blogs/90/MCP_%EC%84%9C%EB%B2%84_%EA%B5%AC%EC%B6%95_%EA%B0%80%EC%9D%B4%EB%93%9C\", \"title\": \"MCP 서버 구축 가이드 - TECH BLOG\", \"content\": \"Tool Calling(툴 콜링)은 LLM(GPT-4, Claude 등) Agent가 외부 함수(도구, API, DB, 파일, 플러그인 등)를 \\'동적으로\\' 호출(자동 매핑/체인 실행/결과\", \"score\": 0.531672, \"raw_content\": null}, {\"url\": \"https://uracle.blog/2025/03/28/agent%EC%9D%98-%EA%B8%B0%EB%B0%98%EC%9D%B4-%EB%90%98%EB%8A%94-llm-tool-calling/\", \"title\": \"Agent의 기반이 되는 LLM Tool Calling: ① 개념 알기 - 유라클 블로그\", \"content\": \"AI 에이전트가 단순한 챗봇과 다른 점은 도구 호출(Tool Calling) 능력입니다. 도구 호출은 LLM이 외부 API를 호출하거나, 특정 함수를 실행하거나, 다른\", \"score\": 0.493336, \"raw_content\": null}, {\"url\": \"https://aiandgamedev.com/ai/assistant-api-function-calling/\", \"title\": \"Assistants API \\'함수 호출(Function Calling)\\' 도구를 활용한 최저가 ...\", \"content\": \"OpenAI의 gpt-4-1106-preview 모델을 사용하여, \\'함수 호출\\' 기능을 포함하는 Assistant를 생성합니다. 이 Assistant는 사용자로부터 최저가와 환율 정보\", \"score\": 0.22589478, \"raw_content\": null}, {\"url\": \"https://meetcody.ai/ko/blog/2023%EB%85%84-%EA%B0%80%EC%9E%A5-%ED%81%B0-ai-%EB%8F%84%EA%B5%AC-%EB%B0%8F-%EB%AA%A8%EB%8D%B8-%EC%97%85%EB%8D%B0%EC%9D%B4%ED%8A%B8-20%EA%B0%80%EC%A7%80-with-features/\", \"title\": \"2023년 가장 큰 AI 도구 및 모델 업데이트 20가지 [With Features] - Cody\", \"content\": \"GPT-4는 고급 이미지 및 음성 해설 기능을 갖추고 있어 다양한 혁신과 활용 사례를 실현합니다. ChatGPT-4의 생성 AI는 ChatGPT-3 버전의 500배에\", \"score\": 0.20779322, \"raw_content\": null}, {\"url\": \"https://devocean.sk.com/blog/techBoardDetail.do?ID=167407&boardType=techBlog\", \"title\": \"Function Calling: LLM이 외부 세계와 소통하는 방법 (ft. Qwen, llama ...\", \"content\": \"Function Calling은 LLM이 자연어 요청을 이해하고 적합한 외부 API를 호출해 실시간 정보를 가져오는 기술로, 사용자가 요청한 정보를 보다 정확하고\", \"score\": 0.08120605, \"raw_content\": null}], \"response_time\": 3.58}', name='tavily_search', tool_call_id='37ba0fa2-66d5-4d38-b76d-5cbf54ccc37b'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'tavily_search', 'arguments': '{\"search_depth\": \"advanced\", \"query\": \"LLM tool calling \\\\uc0ac\\\\uc6a9\\\\ubc95\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'models/gemini-2.5-flash-preview-05-20', 'safety_ratings': []}, id='run-fb98e4fb-efd4-4996-9cf1-01fee480c063-0', tool_calls=[{'name': 'tavily_search', 'args': {'search_depth': 'advanced', 'query': 'LLM tool calling 사용법'}, 'id': '6a512e38-0f54-428a-bdb5-0b3d1cd36705', 'type': 'tool_call'}], usage_metadata={'input_tokens': 3633, 'output_tokens': 29, 'total_tokens': 4122, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='{\"query\": \"LLM tool calling 사용법\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://medium.com/@developer.yasir.pk/tool-calling-for-llms-a-detailed-tutorial-a2b4d78633e2\", \"title\": \"Tool Calling for LLMs: A Detailed Tutorial | by Explore With Yasir\", \"content\": \"Tool calling allows an LLM to interact with external tools during conversation generation. This means the LLM can access information or perform actions beyond its own knowledge base. Tools can be functions written by developers, APIs for external services, or any resource the LLM can interact with.\\\\n\\\\nHow to Achieve Tool Calling\\\\n\\\\nHere’s a breakdown of the steps involved:\\\\n\\\\nDefine Your Tools:\\\\n\\\\nPrepare the Conversation:\\\\n\\\\nPass Tools to the LLM:\\\\n\\\\nInterpret LLM Output:\\\\n\\\\nExecute Tool Calls: [...] The code then demonstrates capturing the LLM’s tool call, calling the function with its arguments, and adding the result (a dummy value of 22.0) to the conversation history. Finally, it shows how to continue the conversation by feeding the updated history back to the LLM.\\\\n\\\\nBenefits of Tool Calling\\\\n\\\\nTool calling allows LLMs to:\\\\n\\\\nThis makes LLMs more versatile and powerful for various applications.\\\\n\\\\nAdditional Notes [...] Incorporate Tool Results:\\\\n\\\\nContinue Conversation:\\\\n\\\\nThe Complete Example\\\\n\\\\nThe provided code demonstrates using tool calling with a weather bot. The bot uses functions get_current_temperature and get_current_wind_speed to retrieve (simulated) weather data. The LLM infers the user wants the temperature in Celsius and suggests calling get_current_temperature.\", \"score\": 0.8332299, \"raw_content\": null}, {\"url\": \"https://velog.io/@nylonmask/chat-completion-api-%EC%97%90%EC%84%9C%EC%9D%98-tool-calls\", \"title\": \"chat completion api 의 function call - velog\", \"content\": \"chat completion api 의 function call\\\\n\\\\nFunction calling (tool calls)\\\\n\\\\nhttps://platform.openai.com/docs/guides/function-calling\\\\n\\\\n결론 부터 말하면 function calling은 llm이 사용자의 질의를 읽고, 로컬 코드에 구현된 함수 중에 어떤 걸 호출할지 선택하는 기능이다.\\\\n\\\\nfunction call의 lifecycle\\\\n\\\\n\\\\n\\\\n여기서 주의할 점은, llm이 해당 함수를 직접 실행하는 것이 아니다. llm은 단지 3번째 단계에서 해당 function을 실행하는데 필요한 arguments를 생성해서 사용자에게 넘겨줄 뿐이다. 사용자는 이 파라미터를 받아서 알아서 쓰면 된다.\\\\n\\\\nfunction calling 사용법 [...] tool calls는 여러 개의 함수를 정의해서 llm에게 알려주면, llm이 사용자의 질의를 보고 어떤 함수를 써야할지 판단하여 호출할 함수 이름 필요한 파라미터 값을 준다. 그럼 agent는 해당 결과를 기반으로 실제 함수를 호출한다.\\\\n\\\\n추가적인 팁\\\\n\\\\n1. 구조화된 출력 사용\\\\n\\\\n복잡한 스키마를 사용할 때 모델이 매개변수를 놓치거나 매개변수의 유형을 잘못 지정할 때가 가끔 있는데, \\\\\"구조화된 출력\\\\\" 기능을 사용하면 함수 호출에 대한 모델 출력이 제공된 스키마와 정확히 일치하도록 보장한다.\\\\nstrict: true. 옵션만 주면 된다. 그냥 켜두는 걸 권장한다.\\\\n\\\\n구조화된 출력을 활성화하면 OpenAI API는 첫 번째 요청 시 제공된 스키마를 사전 처리한 다음 이 아티팩트를 사용하여 모델을 스키마에 맞게 제한한다.\\\\n\\\\n모델은 몇 가지 상황을 제외하고 항상 정확한 스키마를 따른다.\\\\n\\\\n2. tool_choice를 사용해 함수 호출 동작 구성 [...] 아래 예시는 사용자의 배달 주문을 도울 수 있는 대화형 assistant의 예시다. 사용자는 ai기반의 assistant와 채팅할 수 있다. 이 assistant를 유용하게 만들기 위해 주문을 조회하고 사용자 주문에 대한 실제 데이터로 답변할 수 있는 기능을 제공하고자 한다.\\\\n\\\\n1단계: 모델이 호출할 수 있는 코드 베이스의 함수를 선택한다.\\\\n\\\\n코드상에 구현해둔 함수를 선택한다. 이 함수에 대한 정보를 llm에 알려주면, 함수를 실행하기 위해 필요한 arguments를 llm이 생성할 것이다. 배송 날짜를 가져오는 get_delivery_date() 함수를 구현하고 선택한다고 가정하자.\\\\n\\\\n2단계: 모델에 함수를 설명하여 호출 방법을 알려준다.\\\\n\\\\n함수를 선택했으면 모델에 함수를 설명할 \\\\\"함수 정의\\\\\"를 만든다. 이 정의에는 함수가 수행하는 작업(그리고 잠재적으로 언제 호출해야 하는지)과 함수를 호출하는 데 필요한 매개변수를 모두 포함한다.\", \"score\": 0.79022324, \"raw_content\": null}, {\"url\": \"https://dytis.tistory.com/98\", \"title\": \"LangChain을 활용한 Tool Calling # 3 - DEV.DY - 티스토리\", \"content\": \"Tool Calling의 개념\\\\n\\\\nTool Calling은 말 그대로 특정 작업을 수행할 수 있는 툴을 호출하는 것을 의미합니다. 예를 들어, AI가 날씨 정보를 제공해야 할 때, AI가 직접 날씨 API를 호출하여 사용자가 원하는 정보를 전달하는 방식입니다. LangChain을 통해 LLM(Large Language Model)이 직접 툴을 호출하고, 그 결과를 사용하여 사용자에게 답변을 제공할 수 있습니다. Tool Calling에 대한 추가적인 정보는 블로그의 이전 포스트를 참고해주세요.\\\\n\\\\nLLM 어플리케이션에서의 Tool Calling: AI가 더 똑똑해지는 방법\\\\n\\\\nLLM(대형 언어 모델) 어플리케이션이 갈수록 더 많은 일들을 할 수 있게 되면서, \\\\\"Tool calling\\\\\" 기능은 그중에서도 가장 주목할 만한 혁신 중 하나로 자리 잡고 있습니다. 이 기능은 AI가 외부의 도구\\\\n\\\\ndytis.tistory.com [...] Tool calls\\\\n\\\\nLLM 응답에 도구 호출이 포함되는 경우 도구 호출 개체 목록인 .tool_calls 속성으로 해당 메시지나 메시지 청크에 첨부됩니다. chat models는 여러 도구를 동시에 호출할 수 있습니다. ToolCall은 a tool name, dict of argument values, and (optionally) an identifier를 포함하는 typed dict입니다. 도구 호출이 없는 메시지는 이 속성에 대해 기본적으로 빈 목록이 됩니다.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nParsing\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nHow to: pass\\xa0tool\\xa0outputs\\xa0to\\xa0chat\\xa0models\\\\n\\\\nHow to pass tool outputs to chat models | 🦜️🔗 LangChain\\\\n\\\\nThis guide assumes familiarity with the following concepts:\\\\n\\\\npython.langchain.com [...] 런타임에만 알려진 도구에 값을 바인딩해야 할 수도 있습니다. 예를 들어, 도구 로직은 요청을 한 사용자의 ID를 사용해야 할 수도 있습니다. 대부분의 경우, 이러한 값은 LLM에서 제어해서는 안 됩니다. 사실, LLM이 사용자 ID를 제어하도록 허용하면 보안 위험이 발생할 수 있습니다. 대신 LLM은 LLM이 제어하도록 의도된 도구의 parameters만 제어해야 하며, 다른 parameters(예: 사용자 ID)는 애플리케이션 논리에 의해 고정되어야 합니다. 이 방법 가이드에서는 모델이 특정 도구 arguments를 생성하여 런타임에 직접 주입하는 것을 방지하는 방법을 보여줍니다.\\\\n\\\\n\\\\n\\\\n모델에서 arguments 숨기기\\\\n\\\\n이러한 도구의 입력 스키마를 살펴보면 user_id가 여전히 나열되어 있는 것을 볼 수 있습니다.\\\\n\\\\n\\\\n\\\\n하지만 도구 호출을 위해 모델에 전달되는 도구 호출 스키마를 살펴보면 user_id가 제거되었습니다.\", \"score\": 0.780947, \"raw_content\": null}, {\"url\": \"https://medium.com/@craftsangjae/llm-agent-%EA%B0%9C%EB%B0%9C%ED%95%98%EA%B8%B0-2-tool-calling-e87e664f23df\", \"title\": \"LLM Agent 개발하기 (2) Tool Calling. 들어가기 앞서 - Medium\", \"content\": \"LLM은 기본적으로 Text을 받아, Text를 반환하는 함수입니다. LLM은 직접 함수를 실행시킬 수 있는 기능은 없습니다. 하지만 LLM은 어떤 함수를 어떻게 호출해야 하는지를추론할 수 있습니다.\\\\n\\\\nLLM이 위 함수를 활용해서,아래 문장을 통해 어떤 함수를 호출하면 될지를 추론(Reasoning)하도록 만들면 됩니다.\\\\n\\\\nLangchain에서 제공하는 Tool 데코레이터\\\\n\\\\nLLM이 저런 함수를 다룰 수 있도록 Langchain Tool 이 존재합니다. LLM에게 먼저 함수에 대해 구체적으로 설명해주어야 합니다. 이를 위해 아래와 같이 함수에 Docstring을 추가하고, @tool(parse_docstring=True) 을 추가합니다. [...] LLM 모델은 과거 데이터에 기반해있기 때문에, 현재의 정보를 요청한다면 위처럼 거부합니다. 그렇기 때문에 LLM이 현재 주가 정보를 확보할 수 있는 방법이 필요합니다.\\\\n\\\\n외부도구 : Python을 통한 주식 가격 조회\\\\n\\\\n파이썬 패키지 중 하나인 `yfinance`는 편리하게 금융 정보를 조회할 수 있습니다. yfinance를 활용해서 주식 정보를 조회해 보도록 하겠습니다.\\\\n\\\\n이렇게 작성한 함수를 통해, 우리는 원하는 정보들을 쉽게 가져올 수 있습니다.\\\\n\\\\nLLM이 위 함수를 이용할 수 있다면, 우리에게 원하는 답변을 말할 수 있지 않을까요? LLM에게 어떤 도구가 있는지를 알려주어서 해당 도구를 사용할 수 있도록 만드는 것이 바로 `Tool Calling` 입니다.\\\\n\\\\nTool Calling: LLM이 Action을 수행하는 방법 [...] Sign up\\\\n\\\\nSign in\\\\n\\\\nSign up\\\\n\\\\nSign in\\\\n\\\\nLLM Agent 개발하기 (2) Tool Calling\\\\n\\\\n--\\\\n\\\\nShare\\\\n\\\\n들어가기 앞서\\\\n\\\\n이 시리즈의 두 번째 글로, LLM에게 외부의 도구들을 연동하는 방법인 Tool Calling을 다뤄보도록 하겠습니다.\\\\n\\\\nLLM이 할 수 없는 일들이 많습니다. 예를 들면, 지금 날씨가 어떤지 묻거나, 오늘 있었던 사건사고를 물으면, 이에 대한 정보가 없는 LLM은 적절한 대답을 할 수 없습니다. 하지만, 외부의 도구를 적절히 제공해준다면, LLM은 처리해낼 수 있습니다. 이렇게 LLM에게 도구를 제공하는 방법이 바로 “Tool Calling”입니다.\\\\n\\\\nLLM이 풀지 못하는 문제: 지금 엔비디아 주가 얼마야?\\\\n\\\\nLLM은 학습한 시점의 기억만을 가지고 있습니다. LLM에게 오늘의 날짜를 물어보면, 그들은 현재 날짜가 아닌, 그들 기억 속의 날짜를 답변합니다. 그렇기 때문에 아래와 같이 실행하면 LLM은 아래와 같이 답변합니다.\", \"score\": 0.76194656, \"raw_content\": null}, {\"url\": \"https://uracle.blog/2025/03/28/agent%EC%9D%98-%EA%B8%B0%EB%B0%98%EC%9D%B4-%EB%90%98%EB%8A%94-llm-tool-calling/\", \"title\": \"Agent의 기반이 되는 LLM Tool Calling: ① 개념 알기 - 유라클 블로그\", \"content\": \"LLM Tool Calling에서 도구(Tool)이란? LLM이 외부 세계와 상호작용하기 위해 사용하는 인터페이스입니다. 이는 특정 작업을 수행하는 함수(예: 날씨 정보\", \"score\": 0.7576693, \"raw_content\": null}, {\"url\": \"https://dytis.tistory.com/95\", \"title\": \"LLM 어플리케이션에서의 Tool Calling: AI가 더 똑똑해지는 방법\", \"content\": \"1) Tool creation ... Tool을 생성하는 데 권장되는 방법은 @tool 데코레이터를 사용하는 것입니다. from langchain_core.tools import tool @tool\", \"score\": 0.7548612, \"raw_content\": null}, {\"url\": \"https://usingsystem.tistory.com/566\", \"title\": \"[AI] LangChain - Tool Calling 사용법 - 발자취 - 티스토리\", \"content\": \"LLM이 Tool Calling을 통해 도구를 호출했을 때 이름으로 나옵니다. 어떤 툴을 호출했는지 이름을 기준으로 분기해서 실행 시킬 수 있습니다. tool_calls\", \"score\": 0.68064564, \"raw_content\": null}, {\"url\": \"https://www.youtube.com/watch?v=zCwuAlpQKTM&pp=0gcJCdgAo7VqN5tD\", \"title\": \"Tool Calling with LangChain - YouTube\", \"content\": \"Comments · LLM Function Calling - AI Tools Deep Dive · Fully local tool calling with Ollama · Function Calling with LLM using LangChain + Ollama.\", \"score\": 0.5914643, \"raw_content\": null}, {\"url\": \"https://wikidocs.net/261566\", \"title\": \"Part 4. LangChain Agent - 도구 호출 (Tool Calling) - 위키독스\", \"content\": \"도구 호출(Tool Calling)은 LangChain에서 언어 모델이 외부 도구나 API를 사용할 수 있게 해주는 중요한 기능입니다. 이를 통해 AI 모델은 실시간 정보 검색, 계산,\", \"score\": 0.528169, \"raw_content\": null}, {\"url\": \"https://devocean.sk.com/blog/techBoardDetail.do?ID=167407&boardType=techBlog\", \"title\": \"Function Calling: LLM이 외부 세계와 소통하는 방법 (ft. Qwen, llama ...\", \"content\": \"5.2.3 TOOL의 정의. 주식 정보를 가져오는 함수 get_kospi_stock_info 에 대해 JSON 스키마 형식으로 함수를 정의합니다. TOOLS = [\", \"score\": 0.5172057, \"raw_content\": null}], \"response_time\": 3.42}', name='tavily_search', tool_call_id='6a512e38-0f54-428a-bdb5-0b3d1cd36705'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'tavily_extract', 'arguments': '{\"urls\": [\"https://dytis.tistory.com/98\", \"https://digitalbourgeois.tistory.com/885\", \"https://dytis.tistory.com/95\", \"https://claremont.tistory.com/entry/%EC%83%9D%EC%84%B1%ED%98%95-AI-LLM%EC%9D%98-Tool-Calling%EB%8F%84%EA%B5%AC-%ED%98%B8%EC%B6%9C%EC%9D%B4%EB%9E%80\", \"https://velog.io/@byu0hyun/AIMessage-ToolMessage-Tool-Calling-%ED%9D%90%EB%A6%84-%EC%9D%B4%ED%95%B4\", \"https://uracle.blog/2025/03/28/agent%EC%9D%98-%EA%B8%B0%EB%B0%98%EC%9D%B4-%EB%90%98%EB%8A%94-llm-tool-calling/\", \"https://aiandgamedev.com/ai/assistant-api-function-calling/\", \"https://medium.com/@developer.yasir.pk/tool-calling-for-llms-a-detailed-tutorial-a2b4d78633e2\", \"https://velog.io/@nylonmask/chat-completion-api-%EC%97%90%EC%84%A4%EC%9D%98-tool-calls\", \"https://medium.com/@craftsangjae/llm-agent-%EA%B0%9C%EB%B0%9C%ED%95%98%EA%B8%B0-2-tool-calling-e87e664f23df\"]}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'models/gemini-2.5-flash-preview-05-20', 'safety_ratings': []}, id='run-edec9e60-7133-4349-8680-ea5d1b101477-0', tool_calls=[{'name': 'tavily_extract', 'args': {'urls': ['https://dytis.tistory.com/98', 'https://digitalbourgeois.tistory.com/885', 'https://dytis.tistory.com/95', 'https://claremont.tistory.com/entry/%EC%83%9D%EC%84%B1%ED%98%95-AI-LLM%EC%9D%98-Tool-Calling%EB%8F%84%EA%B5%AC-%ED%98%B8%EC%B6%9C%EC%9D%B4%EB%9E%80', 'https://velog.io/@byu0hyun/AIMessage-ToolMessage-Tool-Calling-%ED%9D%90%EB%A6%84-%EC%9D%B4%ED%95%B4', 'https://uracle.blog/2025/03/28/agent%EC%9D%98-%EA%B8%B0%EB%B0%98%EC%9D%B4-%EB%90%98%EB%8A%94-llm-tool-calling/', 'https://aiandgamedev.com/ai/assistant-api-function-calling/', 'https://medium.com/@developer.yasir.pk/tool-calling-for-llms-a-detailed-tutorial-a2b4d78633e2', 'https://velog.io/@nylonmask/chat-completion-api-%EC%97%90%EC%84%A4%EC%9D%98-tool-calls', 'https://medium.com/@craftsangjae/llm-agent-%EA%B0%9C%EB%B0%9C%ED%95%98%EA%B8%B0-2-tool-calling-e87e664f23df']}, 'id': 'fe7e93c3-542f-4a02-a356-825604f7fa93', 'type': 'tool_call'}], usage_metadata={'input_tokens': 6982, 'output_tokens': 468, 'total_tokens': 9264, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='{\"results\": [{\"url\": \"https://dytis.tistory.com/98\", \"raw_content\": \"\\\\n\\\\nLangChain을 활용한 Tool Calling # 3\\\\n\\\\n\\\\n\\\\n자연어 처리와 대화형 AI 모델을 통해 복잡한 문제를 해결하려면, 단순히 언어를 이해하는 것을 넘어서 다양한 툴을 활용할 필요가 있습니다. LangChain은 이러한 필요성을 충족시킬 수 있는 프레임워크로, 특히 Tool Calling 기능을 통해 외부 데이터와의 상호작용을 쉽게 만들어 줍니다. 이 글에서는 LangChain을 활용한 Tool Calling의 작동 원리와 실제 사용 방법을 구체적인 예제를 통해 소개하겠습니다.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nLangChain이란?\\\\n\\\\nLangChain은 자연어 처리 모델을 좀 더 강력하고 유연하게 사용할 수 있게 도와주는 Python 기반의 오픈소스 프레임워크입니다. 이 프레임워크는 AI 모델과 다양한 외부 도구를 연결하는 데 초점을 맞추고 있어, AI 모델이 API 호출, 데이터베이스 쿼리, 계산 작업 등을 직접 수행하도록 할 수 있습니다. Tool Calling은 이러한 외부 툴들과의 상호작용을 통해 문제를 해결하는 데 사용되는 LangChain의 핵심 기능 중 하나입니다. LangChain에 대한 추가적인 정보는 블로그의 이전 포스트를 참고해주세요.\\\\n\\\\nLLM 애플리케이션 개발 훑어보기 - LangChain #1 Intro 및 QuickStart\\\\n\\\\nIntroduction LangChain은 인공 지능(AI) 및 그 기계 학습 하위 집합으로 작업하는 소프트웨어 개발자가 대규모 언어 모델을 다른 외부 구성 요소와 결합하여 LLM 기반 애플리케이션을 개발할 수 있는 오\\\\n\\\\ndytis.tistory.com\\\\n\\\\n\\\\n\\\\nTool Calling의 개념\\\\n\\\\nTool Calling은 말 그대로 특정 작업을 수행할 수 있는 툴을 호출하는 것을 의미합니다. 예를 들어, AI가 날씨 정보를 제공해야 할 때, AI가 직접 날씨 API를 호출하여 사용자가 원하는 정보를 전달하는 방식입니다. LangChain을 통해 LLM(Large Language Model)이 직접 툴을 호출하고, 그 결과를 사용하여 사용자에게 답변을 제공할 수 있습니다. Tool Calling에 대한 추가적인 정보는 블로그의 이전 포스트를 참고해주세요.\\\\n\\\\nLLM 어플리케이션에서의 Tool Calling: AI가 더 똑똑해지는 방법\\\\n\\\\nLLM(대형 언어 모델) 어플리케이션이 갈수록 더 많은 일들을 할 수 있게 되면서, \\\\\"Tool calling\\\\\" 기능은 그중에서도 가장 주목할 만한 혁신 중 하나로 자리 잡고 있습니다. 이 기능은 AI가 외부의 도구\\\\n\\\\ndytis.tistory.com\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nHow to: use\\xa0chat\\xa0models\\xa0to\\xa0call\\xa0tools\\\\n\\\\nHow to use chat models to call tools | 🦜️🔗 LangChain\\\\n\\\\nThis guide assumes familiarity with the following concepts:\\\\n\\\\npython.langchain.com\\\\n\\\\n\\\\n\\\\n채팅 모델은 주어진 프롬프트에 \\\\\"Tool calling\\\\\"을 통해 응답할 수 있습니다. \\\\\"Tool calling\\\\\"이라는 이름이 모델이 직접 어떤 동작을 수행한다는 것을 의미하지만, 실제로는 그렇지 않습니다! 모델은 도구에 대한 인수만 생성하고, 실제로 도구를 실행(또는 실행하지 않음)하는 것은 사용자에게 달려 있습니다.\\\\n\\\\nTool calling은 모델에서 구조화된 출력을 생성하는 일반적인 기술이며, 도구를 호출할 의도가 없을 때에도 사용할 수 있습니다. 그 사용 사례의 예로는 구조화되지 않은 텍스트에서 추출하는 것이 있습니다.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n예제\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nTool calls\\\\n\\\\nLLM 응답에 도구 호출이 포함되는 경우 도구 호출 개체 목록인 .tool_calls 속성으로 해당 메시지나 메시지 청크에 첨부됩니다. chat models는 여러 도구를 동시에 호출할 수 있습니다. ToolCall은 a tool name, dict of argument values, and (optionally) an identifier를 포함하는 typed dict입니다. 도구 호출이 없는 메시지는 이 속성에 대해 기본적으로 빈 목록이 됩니다.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nParsing\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nHow to: pass\\xa0tool\\xa0outputs\\xa0to\\xa0chat\\xa0models\\\\n\\\\nHow to pass tool outputs to chat models | 🦜️🔗 LangChain\\\\n\\\\nThis guide assumes familiarity with the following concepts:\\\\n\\\\npython.langchain.com\\\\n\\\\n일부 모델은 도구 호출이 가능합니다. 즉, 특정 사용자가 제공한 스키마에 맞는 인수를 생성합니다. 이 가이드에서는 이러한 도구 호출을 사용하여 실제로 함수를 호출하고 결과를 모델에 올바르게 다시 전달하는 방법을 보여줍니다.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n예제\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n다음으로, 모델에 채워진 인수를 사용하여 도구 함수를 호출해 보겠습니다!\\\\n\\\\n편리하게도 ToolCall을 사용하여 LangChain 도구를 호출하면 모델에 피드백할 수 있는 ToolMessage가 자동으로 반환됩니다.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n마지막으로, 도구 결과를 사용하여 모델을 호출합니다. 모델은 이 정보를 사용하여 원래 쿼리에 대한 최종 답변을 생성합니다.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nHow to: pass\\xa0run\\xa0time\\xa0values\\xa0to\\xa0tools\\\\n\\\\nHow to pass run time values to tools | 🦜️🔗 LangChain\\\\n\\\\n<Prerequisites titlesAndLinks={[\\\\n\\\\npython.langchain.com\\\\n\\\\n런타임에만 알려진 도구에 값을 바인딩해야 할 수도 있습니다. 예를 들어, 도구 로직은 요청을 한 사용자의 ID를 사용해야 할 수도 있습니다. 대부분의 경우, 이러한 값은 LLM에서 제어해서는 안 됩니다. 사실, LLM이 사용자 ID를 제어하도록 허용하면 보안 위험이 발생할 수 있습니다. 대신 LLM은 LLM이 제어하도록 의도된 도구의 parameters만 제어해야 하며, 다른 parameters(예: 사용자 ID)는 애플리케이션 논리에 의해 고정되어야 합니다. 이 방법 가이드에서는 모델이 특정 도구 arguments를 생성하여 런타임에 직접 주입하는 것을 방지하는 방법을 보여줍니다.\\\\n\\\\n\\\\n\\\\n모델에서 arguments 숨기기\\\\n\\\\n이러한 도구의 입력 스키마를 살펴보면 user_id가 여전히 나열되어 있는 것을 볼 수 있습니다.\\\\n\\\\n\\\\n\\\\n하지만 도구 호출을 위해 모델에 전달되는 도구 호출 스키마를 살펴보면 user_id가 제거되었습니다.\\\\n\\\\n따라서 도구를 호출할 때 user_id를 전달해야 합니다.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n하지만 모델이 도구를 호출하면 user_id 인수가 생성되지 않습니다.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n런타임에 arguments 주입\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nuser_to_pets 사전을 살펴보면 고양이와 앵무새를 포함하도록 업데이트된 것을 볼 수 있습니다.\\\\n\\\\n\\\\n\\\\n\\'AI > 어플리케이션 개발\\' 카테고리의 다른 글\\\\n\\\\nMCP(Model Context Protocol)이 뭐길래?(3) | 2025.03.20\\\\nLangChain을 활용한 Tool Calling # 4(3) | 2024.11.29\\\\nLangChain을 활용한 Tool Calling # 2(3) | 2024.11.29\\\\nLangChain을 활용한 Tool Calling # 1(2) | 2024.11.29\\\\nLLM 어플리케이션에서의 Tool Calling: AI가 더 똑똑해지는 방법(0) | 2024.11.29\\\\n인기 글\\\\n\\\\n최근 댓글\\\\n\\\\n최근 글\\\\n\\\\n티스토리툴바\\\\n\\\\n\\\\n\\\\n\", \"images\": []}, {\"url\": \"https://aiandgamedev.com/ai/assistant-api-function-calling/\", \"raw_content\": \"AI&GameDev\\\\n\\\\nAI와 게임개발에 관련된 이야기\\\\n\\\\nAssistants API ‘함수 호출(Function calling)’ 도구를 활용한 최저가 확인 챗봇 구현하기\\\\n\\\\n이전 포스팅에서 다룬 Assistants API의 기본 사용법과 Retrieval 도구 사용에 이어, 이번 글에서는 ‘함수 호출(Function calling)’ 도구의 활용법을 알아보고, 이를 통해 간단한 ‘해외직구 최저가 확인 챗봇’을 구현하는 과정을 소개합니다.\\\\n\\\\n목차\\\\n\\\\n해외직구 최저가 확인 챗봇\\\\n\\\\nOpenAI의 Assistants API는 다양한 애플리케이션 개발에 유용한 도구를 제공하며, 특히 ‘함수 호출’ 기능은 챗봇이 사용자 정의 함수를 활용할 수 있게 해주는 강력한 기능입니다. 본 글에서는 사용자가 어떤 물품을 구입하려고 할 때 해외 쇼핑몰의 최저가와 환율을 확인한 후에 한화로 최저가를 제공하는 ‘최저가 확인 챗봇’ 기능을 구현하려고 합니다. 이 예시는 실제 상품 검색이나 환율 조회 기능을 포함하지 않고, ‘함수 호출’ 기능의 사용법을 이해하는 데 중점을 둡니다.\\\\n\\\\nRetrieval 도구를 사용한 챗봇 구현은 OpenAI Assistants API와 Retrieval로 챗봇 만들기: 5단계 완전 가이드 에 정리되어 있으니 확인해 보시면 좋을 것 같습니다.\\\\n\\\\n함수호출 (Function calling)\\\\n\\\\n‘함수 호출’ 기능은 Assistant가 사용자가 사전에 정의한 함수를 사용할 수 있도록 합니다. 이 기능의 핵심은 Assistant가 직접 함수를 호출하는 것이 아니라, 필요한 정보를 얻기 위해 사용자에게 함수 호출을 요청하고, 사용자가 제공한 결과를 바탕으로 응답을 생성한다는 점입니다.\\\\n\\\\n참고로 OpenAI 사이트에서 확인할 수 있는 Function calling에 대한 기본적인 설명은 다음과 같습니다.platform.openai.com/docs/assistants/tools/function-calling\\\\n\\\\n개발과정 (Assistants API, Function calling)\\\\n\\\\n개발을 위한 기본 설정 및 준비는 “OpenAI의 Assistants API: 인공지능 기반 ChatGPT 챗봇 개발의 새로운 지평“의 “Python으로 Assistants API 실행” 부분을 참조하세요.\\\\n\\\\nJSON 파일 출력을 위한 함수\\\\n\\\\n코드 실행 시 출력값이 줄바꿈이 되어 있지 않아 가독성을 높이기 위해 작성하였습니다.\\\\n\\\\nAssistant 생성\\\\n\\\\nOpenAI의\\xa0gpt-4-1106-preview\\xa0모델을 사용하여, ‘함수 호출’ 기능을 포함하는 Assistant를 생성합니다. 이 Assistant는 사용자로부터 최저가와 환율 정보를 받아 최종 가격을 계산하여 제공합니다. 최저가와 환율을 확인하는 2개의 함수를 구현하였습니다.\\\\n\\\\ntools에\\xa0function이 2개 포함되어 있는 것을 확인할 수 있습니다.\\\\n\\\\nMessage를 포함한 Thread 생성\\\\n\\\\n아이폰을 해외 직구로 구매할 때 가격을 확인하는 메세지가 포함된 Thread 입니다.\\\\n\\\\n정상적으로 Thread가 생성되었습니다.\\\\n\\\\nRun 생성\\\\n\\\\n메세지가 포함된 Thread를 실행해 보겠습니다.\\\\n\\\\nRun의 상태를 확인하는 코드\\\\n\\\\n처음 Run을 생성하면 status가 queued 상태입니다. 이후 진행 중일 때에는 status가 in_progress가 되고 답변이 완료되면 completed 상태가 됩니다. 함수호출 시에는 requires_action 상태가 추가되는데 요청을 수행하기 위해 함수호출이 필요한 상태임을 나타냅니다.그러므로 queued 혹은 in_progress 인 경우 time.sleep(2)으로 대기, required_action 시에는 사용자가 함수호출을 수행, completed 시에는 요청이 완료된 상태이므로 메세지의 결과를 확인합니다.\\\\n\\\\nRun을 생성하고 작업이 진행되면 추가적인 함수 호출이 필요한 상태(required_action)가 되어 다음과 같은 결과를 출력합니다.\\xa0required_action\\xa0부분에서 어떤 함수 호출이 필요한지 확인할 수 있습니다.\\\\n\\\\nRun 실행에 필요한 Function 확인\\\\n\\\\n호출이 필요한 함수는 다음과 같이 확인 할 수 있습니다.\\\\n\\\\n결과는 다음과 같습니다.\\xa0RequiredActionFunctionToolCall의\\xa0id는 함수를 호출하기 위해 필요한 값이 됩니다.\\\\n\\\\n또한 필요한 함수를 확인하면서 Assistant 가 예측한 파라메터를 확인할 수 있는데 이번에는 product_name과 us_price 값 중 us_price 값만 수동으로 설정합니다.\\\\n\\\\nproduct_name과 us_price 값이 적용된 다음과 같은 값을 얻을 수 있습니다.\\\\n\\\\nFunction calling\\\\n\\\\noutput에\\xa0product_name과\\xa0us_price\\xa0를 넣고 앞서 확인한 함수의\\xa0id\\xa0로 함수를 호출합니다.실제 상용 서비스를 개발하는 경우 최저가를 검색하는 기능은 자체 서비스 구현 혹은 크롤링을 하거나 지원하는 API가 있다면 이를 사용하고 환율은 다양한 환율 정보를 확인할 수 있는 API나 사이트가 존재하므로 이를 활용하여 값을 적용하면 됩니다.\\\\n\\\\nRun의 status를 확인해 보면 완료(completed)가 아닌 다시 required_action이 되는 것을 확인할 수 있습니다.\\\\n\\\\n이번에는 환율을 설정하는 함수를 호출합니다.\\\\n\\\\nMessage 리스트 출력\\\\n\\\\n환율을 설정하는 함수호출까지 완료하고 작업을 완료하고 Run의 status가 completed가 되면 메세지를 출력합니다.Assistant는 사용자로부터 받은 최저가와 환율 정보를 기반으로 상품의 최저가를 계산하고, 이를 사용자에게 알려줍니다.\\\\n\\\\n결과는 다음과 같습니다. 아이폰의 가격이 899이고 환율이 1340일 때 가격은 1,205,260원이 됨을 알 수 있습니다.\\\\n\\\\nThread 삭제\\\\n\\\\nPlayground에서 Function calling 사용한 해외직구 최저가 확인 챗봇\\\\n\\\\n생성된 Assistant들은 playform.openai.com의 assistants탭에서 확인할 수 있으며 신규 Assistant를 생성할 수도 있습니다.\\\\n\\\\nPlayground에서도 Assistant를 생성할 때 function을 포함시킬 수 있으며 메세지를 추가하고 Run을 실행시키면 getLowestPrice와 getExchangeRate 를 호출하도록 요청합니다. 필요한 값을 기입한 후 submit 을 선택하면 최저가와 환율이 적용된 답변을 얻을 수 있습니다.\\\\n\\\\n정리\\\\n\\\\n지금까지 우리는 Assistants API의 ‘함수 호출’ 도구를 사용하여 간단한 기능을 구현하는 방법을 알아보았습니다. 이 과정을 통해, 우리는 어떻게 이 도구를 활용하여 사용자 정의 기능을 챗봇에 통합할 수 있는지에 대해 확인해 볼 수 있었습니다. 특히, 다른 서비스나 API들과 연동함으로써, 사용자에게 더욱 풍부하고 다양한 기능을 제공할 수 있는 챗봇을 만들 수 있을 것으로 보입니다.\\\\n\\\\n그러나 이 과정에서 한글을 사용할 때 버그가 발생하거나 대답이 일관되지 않는 문제가 있었는데, 이는 Assistants API 자체의 문제인 것으로 보입니다. 이러한 문제들은 사용자 경험을 저해할 수 있으므로, OpenAI 측에서의 지속적인 개선이 요구됩니다.\\\\n\\\\n이러한 문제에도 불구하고, Assistants API의 발전 가능성은 매우 크다고 할 수 있습니다. 현재는 beta 단계에 있지만, 앞으로 이러한 문제들이 수정되고 더 많은 기능이 추가된다면, 더욱 강력하고 다양한 애플리케이션 개발이 가능할 것으로 기대됩니다.\\\\n\\\\n본 글은 GPTers에 게시되고 있습니다.https://www.gpters.org/c/llm/assistants-api-function-calling\\\\n\\\\n글 내비게이션\\\\n\\\\n답글 남기기 응답 취소\\\\n\\\\n댓글을 달기 위해서는 로그인해야합니다.\\\\n\\\\n최신 글\\\\n\\\\n카테고리\\\\n\\\\n보관함\\\\n\\\\n\", \"images\": []}, {\"url\": \"https://medium.com/@developer.yasir.pk/tool-calling-for-llms-a-detailed-tutorial-a2b4d78633e2\", \"raw_content\": \"Published Time: 2024-07-29T19:50:23.959Z\\\\nTool Calling for LLMs: A Detailed Tutorial | by Explore With Yasir | Medium\\\\nOpen in app\\\\nSign up\\\\nSign in\\\\n\\\\nWrite\\\\n\\\\nSign up\\\\nSign in\\\\n\\\\nTool Calling for LLMs: A Detailed Tutorial\\\\n\\\\nExplore With Yasir\\\\n·Follow\\\\n5 min read\\\\n·\\\\nJul 29, 2024\\\\n\\\\n30\\\\n\\\\nListen\\\\nShare\\\\n\\\\nThis tutorial explains what tool calling is for Large Language Models (LLMs) and how to achieve it. It uses the example of a weather bot to illustrate the concepts.\\\\nWhat is Tool Calling?\\\\nTool calling allows an LLM to interact with external tools during conversation generation. This means the LLM can access information or perform actions beyond its own knowledge base. Tools can be functions written by developers, APIs for external services, or any resource the LLM can interact with.\\\\nHow to Achieve Tool Calling\\\\nHere’s a breakdown of the steps involved:\\\\nDefine Your Tools:\\\\n\\\\nWrite functions representing the tools you want the LLM to use.\\\\nThese functions should be well-defined with:\\\\nDescriptive names\\\\nType hints for arguments (e.g., a: float)\\\\nDocstrings explaining function purpose and arguments (using Args: block).\\\\nOptional return type and Returns: block.\\\\n\\\\nPrepare the Conversation:\\\\n\\\\nCreate a list containing your tool functions.\\\\nSet up the conversation history as a list of dictionaries. Each dictionary should include:\\\\n\\\\\"role\\\\\" (e.g., \\\\\"system\\\\\", \\\\\"user\\\\\")\\\\n\\\\\"content\\\\\" (the text spoken by that role)\\\\n\\\\nPass Tools to the LLM:\\\\n\\\\nUse a library function like tokenizer.apply_chat_template to format the conversation history and tool list for the LLM.\\\\nThis function might take additional arguments like chat_template (specifying the tool calling template) and add_generation_prompt (to guide the LLM).\\\\n\\\\nInterpret LLM Output:\\\\n\\\\nAfter processing the conversation and tools, the LLM might suggest tool calls.\\\\nThese calls are usually formatted as JSON objects with:\\\\n\\\\\"name\\\\\" (the tool function name)\\\\n\\\\\"arguments\\\\\" (a dictionary containing arguments for the tool)\\\\n\\\\nExecute Tool Calls:\\\\n\\\\nParse the LLM’s tool call suggestion and extract the function name and arguments.\\\\nCall the corresponding function from your tool list with those arguments.\\\\n\\\\nIncorporate Tool Results:\\\\n\\\\nCapture the results returned by the tool functions.\\\\nAdd these results to the conversation history for further processing by the LLM.\\\\n\\\\nContinue Conversation:\\\\n\\\\nRepeat steps 3–6 to allow the LLM to potentially use more tools based on the updated conversation history.\\\\n\\\\nThe Complete Example\\\\nThe provided code demonstrates using tool calling with a weather bot. The bot uses functions get_current_temperature and get_current_wind_speed to retrieve (simulated) weather data. The LLM infers the user wants the temperature in Celsius and suggests calling get_current_temperature.\\\\nThe code then demonstrates capturing the LLM’s tool call, calling the function with its arguments, and adding the result (a dummy value of 22.0) to the conversation history. Finally, it shows how to continue the conversation by feeding the updated history back to the LLM.\\\\n# Define helper functions for weather (replace with actual data retrieval)\\\\ndef get_current_temperature(location: str, unit: str) -> float:\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    Simulates getting the current temperature at a location.  \\\\nArgs:  \\\\n    location: The location to get the temperature for, in the format \\\\\"City, Country\\\\\".  \\\\n    unit: The unit to return the temperature in (e.g., \\\\\"celsius\\\\\", \\\\\"fahrenheit\\\\\").\\\\n\\\\nReturns:  \\\\n    A dummy value (22.0) for demonstration purposes.   \\\\n    Replace this with actual temperature retrieval logic.  \\\\n\\\\\"\\\\\"\\\\\"  \\\\nreturn 22.0  \\\\\\\\# Replace with actual temperature retrieval\\\\n\\\\ndef get_current_wind_speed(location: str) -> float:\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    Simulates getting the current wind speed at a location.  \\\\nArgs:  \\\\n    location: The location to get the wind speed for, in the format \\\\\"City, Country\\\\\".\\\\n\\\\nReturns:  \\\\n    A dummy value (6.0) for demonstration purposes.  \\\\n    Replace this with actual wind speed retrieval logic.  \\\\n\\\\\"\\\\\"\\\\\"  \\\\nreturn 6.0  \\\\\\\\# Replace with actual wind speed retrieval\\\\n\\\\n# Define your tool list (functions the LLM can call)\\\\ntools = [get_current_temperature, get_current_wind_speed]  \\\\n# Assuming you have a pre-loaded tokenizer (replace with your actual loading logic)\\\\n# ... tokenizer is loaded ...  \\\\n# Set up the conversation history\\\\nmessages = [\\\\n  {\\\\\"role\\\\\": \\\\\"system\\\\\", \\\\\"content\\\\\": \\\\\"You are a bot that responds to weather queries. You should reply with the unit used in the queried location.\\\\\"},\\\\n  {\\\\\"role\\\\\": \\\\\"user\\\\\", \\\\\"content\\\\\": \\\\\"Hey, what\\'s the temperature in Paris right now?\\\\\"}\\\\n]  \\\\n# Prepare the model input with conversation history, tools, and additional arguments\\\\ninputs = tokenizer.apply_chat_template(\\\\n    messages,\\\\n    chat_template=\\\\\"tool_use\\\\\",  # Specify the tool calling template\\\\n    tools=tools,\\\\n    add_generation_prompt=True,  # Add a prompt to guide the LLM\\\\n    return_dict=True,\\\\n    return_tensors=\\\\\"pt\\\\\"\\\\n)  \\\\n# Move the inputs to the device the model is on (if using GPU)\\\\ninputs = {k: v.to(model.device) for k, v in inputs.items()}  \\\\n# Generate the LLM response with the prepared inputs\\\\nout = model.generate(**inputs, max_new_tokens=128)  \\\\n# Decode the LLM output and print it\\\\nprint(tokenizer.decode(out[0][len(inputs[\\\\\"input_ids\\\\\"][0]):]))  \\\\n# Simulate the LLM suggesting a tool call (based on the conversation)\\\\ntool_call_id = \\\\\"vAHdf3\\\\\"  # Random and unique ID for each tool call\\\\ntool_call = {\\\\n  \\\\\"name\\\\\": \\\\\"get_current_temperature\\\\\",\\\\n  \\\\\"arguments\\\\\": {\\\\\"location\\\\\": \\\\\"Paris, France\\\\\", \\\\\"unit\\\\\": \\\\\"celsius\\\\\"}\\\\n}  \\\\n# Add the suggested tool call to the conversation history\\\\nmessages.append({\\\\n  \\\\\"role\\\\\": \\\\\"assistant\\\\\",\\\\n  \\\\\"tool_calls\\\\\": [{\\\\\"id\\\\\": tool_call_id, \\\\\"type\\\\\": \\\\\"function\\\\\", \\\\\"function\\\\\": tool_call}]\\\\n})  \\\\n# Simulate executing the tool call (replace with actual function call)\\\\n# This retrieves the \\\\\"dummy\\\\\" temperature using the defined function\\\\ntemperature = get_current_temperature(tool_call[\\\\\"arguments\\\\\"][\\\\\"location\\\\\"], tool_call[\\\\\"arguments\\\\\"][\\\\\"unit\\\\\"])  \\\\n# Add the tool call result to the conversation history\\\\nmessages.append({\\\\n  \\\\\"role\\\\\": \\\\\"tool\\\\\",\\\\n  \\\\\"tool_call_id\\\\\": tool_call_id,\\\\n  \\\\\"name\\\\\": \\\\\"get_current_temperature\\\\\",\\\\n  \\\\\"content\\\\\": str(temperature)  # Convert temperature to string\\\\n})  \\\\n# Prepare the model input again with the updated conversation history\\\\ninputs = tokenizer.apply_chat_template(\\\\n    messages,\\\\n    chat_template=\\\\\"tool_use\\\\\",\\\\n    tools=tools,\\\\n    add_generation_prompt=True,\\\\n    return_dict=True,\\\\n    return_tensors=\\\\\"pt\\\\\"\\\\n)  \\\\n# Move the inputs to the device again\\\\ninputs = {k: v.to(model.device) for k, v in inputs.items()}  \\\\n# Generate the final LLM response with the updated conversation\\\\nout = model.generate(**inputs, max_new_tokens=128)  \\\\n# Decode and print the final LLM response (including temperature)\\\\nprint(tokenizer.decode(out[0][len(inputs[\\\\\"input_ids\\\\\"][0]):]))\\\\nBenefits of Tool Calling\\\\nTool calling allows LLMs to:\\\\n\\\\nAccess real-time information (e.g., weather data)\\\\nPerform calculations (e.g., calculators)\\\\nInteract with external databases and services\\\\nExpand their capabilities beyond stored knowledge\\\\n\\\\nThis makes LLMs more versatile and powerful for various applications.\\\\nAdditional Notes\\\\n\\\\nNot all LLMs support tool calling. Check the documentation of your specific model.\\\\nLibraries like LangChain provide tools and functionalities to simplify LLM communication and tool calling.\\\\nThis tutorial focused on function-based tools. Depending on the LLM, other types of tools (like web APIs) might be supported as well.\\\\n\\\\nBy understanding and implementing tool calling, you can leverage the power of LLMs for more dynamic and interactive applications.\\\\nAbout myself:\\\\nI am Yasir Siddique. As a specialist in Generative AI and Large Language Models (LLMs) and advocate for the possibilities of Machine Learning, I’ve had the privilege of working with cutting-edge technologies like OpenAI and Langchain. My journey extends to being a Microservices Aficionado, well-versed in Python, Java, Node.js, and GoLang. With a deep understanding of Cloud Architecture on AWS, coupled with expertise in DevOps and MLOps, I’m excited to share my insights and experiences in this ever-evolving technological landscape. To explore more about the transformative tech trends and innovations, follow me on Linkedin https://www.linkedin.com/in/yasir-sd/Website https://www.yasirsiddique.com\\\\n\\\\nSign up to discover human stories that deepen your understanding of the world.\\\\nFree\\\\nDistraction-free reading. No ads.\\\\nOrganize your knowledge with lists and highlights.\\\\nTell your story. Find your audience.\\\\nSign up for free\\\\nMembership\\\\nRead member-only stories\\\\nSupport writers you read most\\\\nEarn money for your writing\\\\nListen to audio narrations\\\\nRead offline with the Medium app\\\\nTry for $5/month\\\\nLarge Language Models\\\\nLlm\\\\nPython\\\\nAgents\\\\nArtificial Intelligence\\\\n\\\\n30\\\\n\\\\n30\\\\n\\\\n\\\\n\\\\nFollow\\\\nWritten by Explore With Yasir -----------------------------\\\\n28 Followers\\\\n·4 Following\\\\nFollow\\\\nNo responses yet\\\\n\\\\n\\\\nWrite a response\\\\nWhat are your thoughts?\\\\nCancel\\\\nRespond\\\\nAlso publish to my profile\\\\nMore from Explore With Yasir\\\\n\\\\n\\\\nExplore With Yasir\\\\nUnderstanding Recursive Character Text Splitting ------------------------------------------------ ### RecursiveCharacterTextSplitting in Langchain is a technique for splitting text into smaller chunks based on character boundaries. It…\\\\nJun 5, 2024\\\\n56\\\\n\\\\n\\\\n\\\\nExplore With Yasir\\\\nRun Meta AI’s Llama 3.1 8B: A Hands-on Guide -------------------------------------------- ### Llama 3.1 8B Model\\\\nJul 29, 2024\\\\n111\\\\n\\\\n\\\\n\\\\nExplore With Yasir\\\\nUnderstanding the controllable parameters to run/inference your Large Language Model ------------------------------------------------------------------------------------ ### This article helps understanding the parameters/settings while inferencing your Large Language Model\\\\nJul 7, 2023\\\\n80 1\\\\n\\\\n\\\\n\\\\nExplore With Yasir\\\\nUnderstanding Mixture of Experts in NLP: A Technical Deep Dive -------------------------------------------------------------- ### Introduction\\\\nDec 12, 2023\\\\n1\\\\n\\\\nSee all from Explore With Yasir\\\\nRecommended from Medium\\\\n\\\\n\\\\nMinyang Chen\\\\nCreating Intelligent Agent with OpenAI Agents SDK and Autogen MCP Tools and Memory ---------------------------------------------------------------------------------- ### On March 11, 2025, OpenAI has introduced new sophisticated suite of tools designed to enhance the capabilities of developing powerful…\\\\nMar 23\\\\n5\\\\n\\\\n\\\\n\\\\nIn\\\\nData Science Collective\\\\nby\\\\nGao Dalie (高達烈)\\\\nLangGraph + MCP + Ollama: The Key To Powerful Agentic AI -------------------------------------------------------- ### In this story, I have a super quick tutorial showing you how to create a multi-agent chatbot using LangGraph, MCP, and Ollama to build a…\\\\nMar 28\\\\n939 6\\\\n\\\\n\\\\n\\\\nAakriti Aggarwal\\\\nAI’nt That Easy #27: How to Calculate the Cost of Running LLM-Based Applications in Production ---------------------------------------------------------------------------------------------- ### Launching and scaling an LLM-powered application in production can be expensive. Whether you’re a startup or an enterprise, understanding…\\\\nDec 1, 2024\\\\n2\\\\n\\\\n\\\\n\\\\nYana Stamenova\\\\nIntegrating LLMs with OpenRouter API: A Practical Code Example -------------------------------------------------------------- ### I recently started a side project that required large language models (LLMs). With prior experience using open-source models from…\\\\nDec 15, 2024\\\\n63\\\\n\\\\n\\\\n\\\\nIn\\\\nEveryday AI\\\\nby\\\\nManpreet Singh\\\\nCraziest MCP Servers You Must Try --------------------------------- ### I remember when I first heard about MCP (Model Context Protocol). I thought\\\\nMar 9\\\\n1.3K 13\\\\n\\\\n\\\\n\\\\nKerem Aydın\\\\nHow to Setup Memory in an LLM Agent ----------------------------------- ### When building an LLM agent to accomplish a task, effective memory management is crucial, especially for long and multi-step objectives…\\\\nJan 18\\\\n17 1\\\\n\\\\nSee more recommendations\\\\nHelp\\\\nStatus\\\\nAbout\\\\nCareers\\\\nPress\\\\nBlog\\\\nPrivacy\\\\nRules\\\\nTerms\\\\nText to speech\", \"images\": []}, {\"url\": \"https://medium.com/@craftsangjae/llm-agent-%EA%B0%9C%EB%B0%9C%ED%95%98%EA%B8%B0-2-tool-calling-e87e664f23df\", \"raw_content\": \"Sign up\\\\n\\\\nSign in\\\\n\\\\nSign up\\\\n\\\\nSign in\\\\n\\\\nLLM Agent 개발하기 (2) Tool Calling\\\\n\\\\n--\\\\n\\\\nShare\\\\n\\\\n들어가기 앞서\\\\n\\\\n이 시리즈의 두 번째 글로, LLM에게 외부의 도구들을 연동하는 방법인 Tool Calling을 다뤄보도록 하겠습니다.\\\\n\\\\nLLM이 할 수 없는 일들이 많습니다. 예를 들면, 지금 날씨가 어떤지 묻거나, 오늘 있었던 사건사고를 물으면, 이에 대한 정보가 없는 LLM은 적절한 대답을 할 수 없습니다. 하지만, 외부의 도구를 적절히 제공해준다면, LLM은 처리해낼 수 있습니다. 이렇게 LLM에게 도구를 제공하는 방법이 바로 “Tool Calling”입니다.\\\\n\\\\nLLM이 풀지 못하는 문제: 지금 엔비디아 주가 얼마야?\\\\n\\\\nLLM은 학습한 시점의 기억만을 가지고 있습니다. LLM에게 오늘의 날짜를 물어보면, 그들은 현재 날짜가 아닌, 그들 기억 속의 날짜를 답변합니다. 그렇기 때문에 아래와 같이 실행하면 LLM은 아래와 같이 답변합니다.\\\\n\\\\nLLM 모델은 과거 데이터에 기반해있기 때문에, 현재의 정보를 요청한다면 위처럼 거부합니다. 그렇기 때문에 LLM이 현재 주가 정보를 확보할 수 있는 방법이 필요합니다.\\\\n\\\\n외부도구 : Python을 통한 주식 가격 조회\\\\n\\\\n파이썬 패키지 중 하나인 `yfinance`는 편리하게 금융 정보를 조회할 수 있습니다. yfinance를 활용해서 주식 정보를 조회해 보도록 하겠습니다.\\\\n\\\\n이렇게 작성한 함수를 통해, 우리는 원하는 정보들을 쉽게 가져올 수 있습니다.\\\\n\\\\nLLM이 위 함수를 이용할 수 있다면, 우리에게 원하는 답변을 말할 수 있지 않을까요? LLM에게 어떤 도구가 있는지를 알려주어서 해당 도구를 사용할 수 있도록 만드는 것이 바로 `Tool Calling` 입니다.\\\\n\\\\nTool Calling: LLM이 Action을 수행하는 방법\\\\n\\\\nLLM은 기본적으로 Text을 받아, Text를 반환하는 함수입니다. LLM은 직접 함수를 실행시킬 수 있는 기능은 없습니다. 하지만 LLM은 어떤 함수를 어떻게 호출해야 하는지를추론할 수 있습니다.\\\\n\\\\nLLM이 위 함수를 활용해서,아래 문장을 통해 어떤 함수를 호출하면 될지를 추론(Reasoning)하도록 만들면 됩니다.\\\\n\\\\nLangchain에서 제공하는 Tool 데코레이터\\\\n\\\\nLLM이 저런 함수를 다룰 수 있도록 Langchain Tool 이 존재합니다. LLM에게 먼저 함수에 대해 구체적으로 설명해주어야 합니다. 이를 위해 아래와 같이 함수에 Docstring을 추가하고, @tool(parse_docstring=True) 을 추가합니다.\\\\n\\\\n위와 같이 선언된 함수는 이제 LLM이 이해할 수 있는 형태로 바뀌었습니다. 아래와 같이, 해당 함수에서는 해당 코드가 어떤 동작을 하는지, 어떤 파라미터를 받는지가 명세화되어 있습니다. 이후 LLM은 이 정보를 바탕으로 이 함수를 어떻게 호출하면 되는지를 파악할 수 있습니다.\\\\n\\\\n그리고 LLM에게 bind_tools을 하여 해당 도구가 있다는 것을 알려줍니다.\\\\n\\\\n그러면 이전과 달리 LLM은 content에 응답이 오는 것이 아니라, additional_kwargs에 tool_calls 아래로 담겨 옵니다. 또한 위와 같이 여러 요청이 필요한 작업이 발생할 경우 LLM은 이렇게 N개의 요청을 나누어 제공해줍니다.\\\\n\\\\n여기서 중요한 점은 LLM은 어떤 함수를 호출해야 하는지 추론(Reasoning)만 할 뿐, 실행하진 않습니다. 우리는 LLM의 응답을 통해 실행할 수 있도록 추가적인 작업을 더해야 합니다.\\\\n\\\\ntool_calls의 결과값을 실행시켜, ToolMessage로 변환하기\\\\n\\\\n우선 LLM이 반환한 tool_calls은 아래와 같이 가져올 수 있습니다.\\\\n\\\\n위 응답값을 통해 우리는 아래의 요청 (24년 4월 5일 구글과 애플의 시가(open), 종가(close) 정보를 가져와줘)을 LLM은 2개의 함수 호출로 나누어 추론했음을 알수 있습니다.\\\\n\\\\n`tool_calls` 실행하기\\\\n\\\\n위와 같이 LLM이 추론해낸 tool_calls을 실행합니다. 그리고 그 결과값을 LLM이 이해할 수 있는 메시지 포맷인 ToolMessage로 변환합니다.\\\\n\\\\n위 코드를 통해 우리는 AI가 추론한 Tool 목록을 가지고 메시지를 추론할 수 있습니다.\\\\n\\\\n이렇게 만들어진 Message를 다시 이전 AI 응답값과 함께 넘겨주면 AI는 처리할 수 있습니다. 이제 코드를 완성해보도록 하겠습니다.\\\\n\\\\n마무리: 주식 가격 정보를 알려주는 프롬프트\\\\n\\\\n이렇게 작성한 프롬프트의 예제입니다.\\\\n\\\\n2. 2024년 상반기 동안 구글, 애플, 앤비디아가 이 각각 어떻게 주식 가격이 어떻게 변화했는지 수치로서 설명해 주세요\\\\n\\\\nReference\\\\n\\\\n--\\\\n\\\\n--\\\\n\\\\nWritten by KataCoder\\\\n\\\\n보다 나은 것을 만들기 위해 노력합니다.\\\\n\\\\nNo responses yet\\\\n\\\\nHelp\\\\n\\\\nStatus\\\\n\\\\nAbout\\\\n\\\\nCareers\\\\n\\\\nPress\\\\n\\\\nBlog\\\\n\\\\nPrivacy\\\\n\\\\nRules\\\\n\\\\nTerms\\\\n\\\\nText to speech\\\\n\\\\n\", \"images\": []}, {\"url\": \"https://velog.io/@byu0hyun/AIMessage-ToolMessage-Tool-Calling-%ED%9D%90%EB%A6%84-%EC%9D%B4%ED%95%B4\", \"raw_content\": \"AIMessage, ToolMessage, Tool Calling 흐름 이해\\\\n\\\\nAIMessage, ToolMessage, Tool Calling 완벽 이해: AIMessage → ToolMessage → AIMessage 흐름\\\\n\\\\nAI 기반의 챗봇이나 자동화 시스템을 설계할 때, 단순히 모델이 답변을 생성하는 것이 아니라 외부 API, 데이터베이스, 코드 실행 등의 툴(Tool)을 호출해야 하는 경우가 많습니다.\\\\n이때 Tool Calling(툴 호출) 개념이 사용되며, 대표적으로 OpenAI의 Function Calling이나 LangChain의 Tool 기능이 있습니다.\\\\n\\\\n오늘은 Tool Calling의 핵심 흐름인 AIMessage → ToolMessage → AIMessage 구조를 이해하고, tool_calls 필드가 왜 중요한지 살펴보겠습니다.\\\\n\\\\n1. AIMessage → ToolMessage → AIMessage 흐름이란?\\\\n\\\\nTool Calling 과정에서 메시지는 다음과 같은 흐름을 따릅니다.\\\\n\\\\n① AIMessage (툴 호출 요청)\\\\n\\\\n사용자의 질문을 받은 LLM이 자체적으로 답변을 생성하지 않고, 외부 툴을 호출해야 한다고 판단하면 tool_calls 필드를 포함한 메시지를 생성합니다.\\\\n이때 중요한 점은 LLM이 직접 툴을 실행하는 것이 아니라, 툴을 호출하는 요청만 만든다는 것입니다.\\\\n\\\\n🔹 예제 (AIMessage - Tool 호출 요청)\\\\n\\\\n✔ \\\\\"get_weather\\\\\"라는 툴을 호출해야 함을 나타냄.\\\\n✔ \\\\\"location\\\\\": \\\\\"Seoul\\\\\" 값을 툴에 전달하도록 요청함.\\\\n✔ LLM은 툴을 직접 실행하지 않고, 툴을 호출하는 요청만 생성.\\\\n\\\\n즉, tool_calls이 포함된 AIMessage는 반드시 툴을 실행해야 하며, 툴이 실행되지 않으면 LLM은 후속 응답을 생성할 수 없습니다.\\\\n\\\\n② ToolMessage (툴 실행 및 결과 반환)\\\\n\\\\nAIMessage에서 툴을 호출했으므로, 실제 툴이 실행되고 결과를 반환해야 합니다.\\\\n이 역할을 하는 것이 ToolMessage이며, 툴의 실행 결과를 담고 있습니다.\\\\n\\\\n🔹 예제 (ToolMessage - 툴 실행 결과)\\\\n\\\\n✔ tool_call_id는 AIMessage에서 요청했던 것과 동일해야 함.\\\\n✔ \\\\\"temperature\\\\\": 15, \\\\\"condition\\\\\": \\\\\"Sunny\\\\\"라는 결과를 반환.\\\\n\\\\n즉, 이 단계에서는 실제로 툴이 실행되며, API 호출, 데이터베이스 조회, 코드 실행 등의 작업을 수행하여 결과를 생성합니다.\\\\n\\\\n③ AIMessage (최종 응답 생성)\\\\n\\\\n툴이 반환한 결과를 바탕으로 LLM이 최종적으로 사용자에게 응답할 메시지를 생성합니다.\\\\n\\\\n🔹 예제 (AIMessage - 최종 응답)\\\\n\\\\n✔ LLM이 ToolMessage에서 받은 데이터를 바탕으로 자연어 응답을 생성.\\\\n✔ 툴을 통해 얻은 정보가 사용자에게 제공됨.\\\\n\\\\n2. Tool Calling에서 tool_calls 여부의 중요성\\\\n\\\\n✔ tool_calls이 없는 AIMessage의 의미\\\\n\\\\nAIMessage에는 두 가지 경우가 있습니다.\\\\n\\\\n1️⃣ LLM이 자체적으로 답변을 생성한 경우 (즉, Tool을 호출하지 않음)\\\\n\\\\n2️⃣ 이전 단계에서 Tool을 호출한 후, ToolMessage의 결과를 받아 LLM이 최종 응답을 생성한 경우\\\\n\\\\n➡ 즉, tool_calls이 없는 AIMessage는 \\\\\"이전 단계에서 Tool을 호출했을 수도 있고, 아닐 수도 있다.\\\\\"\\\\n➡ 반면, tool_calls이 포함된 AIMessage는 반드시 Tool을 호출해야 하고, ToolMessage가 없으면 후속 응답을 생성할 수 없다.\\\\n\\\\n3. 전체 흐름 예제 (서울 날씨 조회)\\\\n\\\\n✅ 정상적인 Tool Calling 흐름\\\\n\\\\n1️⃣ 사용자 입력\\\\n\\\\n2️⃣ AIMessage (툴 호출 요청)\\\\n\\\\n3️⃣ ToolMessage (툴 실행 결과 반환)\\\\n\\\\n4️⃣ AIMessage (최종 응답 생성)\\\\n\\\\n4. 마무리: Tool Calling의 핵심 정리\\\\n\\\\n✅ AIMessage의 tool_calls 여부가 핵심\\\\n\\\\n✅ AIMessage → ToolMessage → AIMessage의 필수 구조\\\\n\\\\n✅ Tool Calling의 목적\\\\n\\\\nFunction Calling 이해하기\\\\n\\\\nMCP(Model Context Protocol)란?\\\\n\\\\n0개의 댓글\\\\n\\\\n\", \"images\": []}, {\"url\": \"https://digitalbourgeois.tistory.com/885\", \"raw_content\": \"평범한 직장인이 사는 세상\\\\n\\\\nPOWERED BY TISTORY\\\\n\\\\nSpring AI의 새로운 도구 호출 기능: AI와 API의 강력한 연동 방법!\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n🔎 AI와 API 연동의 새로운 패러다임, Tool Calling\\\\n\\\\nAI 애플리케이션에서 API와의 연동은 필수적입니다. 기존에는 함수 호출(Function Calling) 기능을 사용했지만, Spring AI에서는 이를 대체할 Tool Calling(도구 호출) 기능을 새롭게 도입했습니다.\\\\n\\\\n이번 블로그에서는 Spring AI의 Tool Calling 기능이 무엇인지, 기존 방식과 비교해 어떤 장점이 있는지, 그리고 실제 구현 방법까지 자세히 알아보겠습니다. 🚀\\\\n\\\\n📌 Spring AI Tool Calling이란?\\\\n\\\\nTool Calling(도구 호출)은 AI 모델이 특정 API나 도구를 직접 호출하여 데이터를 가져오거나 연산을 수행할 수 있도록 지원하는 기능입니다.\\\\n\\\\n✅ 이전 방식: 기존에는 함수 호출 API를 사용해 Java의 메서드를 실행했지만, Spring AI에서는 이 API를 더 이상 지원하지 않습니다.✅ 새로운 방식: Tool Calling 기능을 사용하면 Spring Boot 애플리케이션 내에서 AI 모델이 필요한 정보를 자동으로 가져와 처리할 수 있습니다.\\\\n\\\\n\\\\n\\\\n🔍 Tool Calling이 필요한 이유\\\\n\\\\nAI 모델은 기본적으로 학습된 데이터만을 기반으로 동작합니다. 하지만 실시간 데이터(예: 최신 주식 시세, 사용자 데이터 등)를 처리하려면 외부 API나 데이터베이스와의 연동이 필수입니다.\\\\n\\\\n🎯 예제: AI가 실시간 주식 데이터를 활용하는 방법\\\\n\\\\n1️⃣ 사용자가 AI에게 \\\\\"내 주식 포트폴리오의 총 가치는 얼마야?\\\\\"라고 질문2️⃣ AI는 내부 데이터베이스에서 보유 주식 수량을 가져옴3️⃣ AI가 최신 주가 정보를 외부 API에서 호출4️⃣ AI가 모든 데이터를 종합하여 포트폴리오의 총 가치를 계산 후 반환\\\\n\\\\n이처럼 AI가 직접 API를 호출하고 필요한 데이터를 가져올 수 있도록 도와주는 기능이 바로 Tool Calling입니다.\\\\n\\\\n🛠 Spring AI에서 Tool Calling 구현하기\\\\n\\\\nSpring AI의 Tool Calling 기능을 활용해 실제 구현을 진행해 보겠습니다.\\\\n\\\\n1️⃣ 데이터베이스에서 주식 정보 가져오기\\\\n\\\\n우선, 보유한 주식 수량을 조회하는 WalletTools 클래스를 생성합니다.\\\\n\\\\n🔹 @Tool(description = \\\\\"...\\\\\") 애노테이션을 사용해 AI가 이 메서드의 역할을 이해할 수 있도록 설명을 추가합니다.🔹 walletRepository.findAll()을 호출해 모든 보유 주식 정보를 가져옵니다.\\\\n\\\\n2️⃣ 외부 API에서 최신 주식 가격 가져오기\\\\n\\\\n외부 주식 API를 호출하는 StockTools 클래스를 생성합니다.\\\\n\\\\n🔹 @Tool을 활용해 AI가 적절한 메서드를 호출하도록 만듭니다.🔹 @ToolParam을 사용해 메서드에 전달될 매개변수를 정의합니다.🔹 RestTemplate을 이용해 TwelveData API에서 최신 주가 데이터를 가져옵니다.\\\\n\\\\n3️⃣ AI와 연동하여 Tool Calling 실행하기\\\\n\\\\n컨트롤러에서 AI 모델과 연동해 포트폴리오의 총 가치를 계산하는 API를 만듭니다.\\\\n\\\\n🔹 AI 모델이 stockTools와 walletTools을 사용해 필요한 데이터를 가져오도록 설정합니다.🔹 chatClient.tools(stockTools, walletTools).call()을 통해 AI가 자동으로 필요한 데이터를 조회하도록 만듭니다.\\\\n\\\\n🧪 실행 및 테스트\\\\n\\\\n1️⃣ 애플리케이션 실행하기\\\\n\\\\n환경 변수를 설정한 후, Spring Boot 애플리케이션을 실행합니다.\\\\n\\\\n2️⃣ API 호출하여 AI 응답 확인하기\\\\n\\\\n📌 실행하면 AI가 내부 DB에서 주식 보유 수량을 가져오고, 외부 API에서 최신 주가를 가져와 포트폴리오의 총 가치를 계산해 반환합니다.\\\\n\\\\n🎯\\xa0 Spring AI Tool Calling이 주는 이점\\\\n\\\\nSpring AI의 Tool Calling 기능은 기존 함수 호출 방식보다 더욱 유연하고 강력한 AI-API 연동 방식을 제공합니다.\\\\n\\\\n✅ AI가 직접 API를 호출해 필요한 데이터를 실시간으로 가져올 수 있음✅ 데이터베이스, 외부 API와 손쉽게 연동 가능✅ Spring Boot와 간편하게 통합 가능\\\\n\\\\n앞으로 AI 기반 애플리케이션을 개발할 때 Tool Calling을 활용하면 더욱 실용적인 서비스를 만들 수 있을 것입니다. 🚀\\\\n\\\\nhttps://piotrminkowski.com/2025/03/13/tool-calling-with-spring-ai/?fbclid=IwZXh0bgNhZW0CMTEAAR3dzZ0lMnOHX4nGn5pHa1ND1pFqGw3no6YFu1174Oem2nU-d4Fz2-D4e1w_aem_zSiqIzydMjXM7tsu5IYHlg\\\\n\\\\nTool Calling with Spring AI - Piotr\\'s TechBlog\\\\n\\\\nThis article will show you how to use Spring AI support with the most popular AI models for the tool calling feature.\\\\n\\\\npiotrminkowski.com\\\\n\\\\n\\\\n\\\\n\\'인공지능\\' 카테고리의 다른 글\\\\n\\\\n🚀 바이두, 딥시크 추격 위한 AI 모델 공개!(0) | 2025.03.19\\\\nLG AI ‘엑사원 딥’, 글로벌 AI 시장을 뒤흔들다!(0) | 2025.03.19\\\\nSpring AI와 Model Context Protocol(MCP) 활용하여 지능형 챗봇 구축하기(0) | 2025.03.18\\\\nVibe Coding: AI와 함께하는 새로운 개발 패러다임(0) | 2025.03.18\\\\n앤드류 응이 말하는 \\\\\"AI 시대에도 프로그래밍을 배워야 하는 이유\\\\\"(0) | 2025.03.17\\\\n태그\\\\n\\\\n\\'인공지능\\' Related Articles\\\\n\\\\nDESIGN BY TISTORY 관리자\\\\n\\\\n티스토리툴바\\\\n\\\\n\\\\n\\\\n\", \"images\": []}, {\"url\": \"https://claremont.tistory.com/entry/%EC%83%9D%EC%84%B1%ED%98%95-AI-LLM%EC%9D%98-Tool-Calling%EB%8F%84%EA%B5%AC-%ED%98%B8%EC%B6%9C%EC%9D%B4%EB%9E%80\", \"raw_content\": \"Go for IT\\\\n\\\\n[생성형 AI] LLM의 Tool Calling(도구 호출)이란?\\\\n\\\\nㅇTool Calling:\\xa0LLM(Large Language Model)이 외부 도구(함수, API, 데이터베이스 등)를 호출하여 특정 작업을 수행하는 기능\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nLLM 자체가 모든 정보를 가지고 있지 않거나 계산을 직접 수행할 수 없는 경우, 외부 도구를 활용하여 정확한 답변을 생성할 수 있다\\\\n\\\\n\\\\n\\\\n기본적으로 LLM은 훈련된 데이터에 기반하여 응답을 생성하지만, 다음과 같은 한계가 있다\\\\n\\\\n이를 해결하기 위해 Tool Calling 기능이 도입되었다. LLM은 입력된 프롬프트에 따라 적절한 외부 도구를 선택하고, 이를 호출한 후 결과를 바탕으로 최종적인 응답을 생성한다.\\\\n\\\\n\\\\n\\\\nTool Calling의 동작 방식\\\\n\\\\n\\\\n\\\\n(API 호출 예제)\\\\n\\\\n사용자 입력: \\\\\"비트코인의 현재 가격이 얼마야?\\\\\"\\\\n\\\\n\\\\n\\\\nTool Calling 과정:\\\\n\\\\n\\\\n\\\\n(계산기 호출 예제)\\\\n\\\\n사용자 입력: \\\\\"1542 × 283을 계산해줘.\\\\\"\\\\n\\\\n\\\\n\\\\nTool Calling 과정:\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n※ Tool Calling vs RAG\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nTool Calling은 LLM이 외부 도구를 활용하여 보다 정확하고 신뢰할 수 있는 응답을 생성하는 기술이다. 이를 통해 최신 정보를 반영하고, 연산을 수행하며, 다양한 데이터 소스와 연동할 수 있다. AI 비서, 검색 엔진, 금융 데이터 분석, 의료 진단 등 다양한 산업에서 활용되고 있으며, 앞으로 더욱 발전할 것으로 기대된다.\\\\n\\\\n\\'인공지능 > 생성형 AI\\' 카테고리의 다른 글\\\\n\\\\n[생성형 AI] LangChain이란?(0) | 2025.02.17\\\\n[생성형 AI] AGI(Artificial General Intelligence): 인공지능의 최종 목표(1) | 2025.02.17\\\\n[생성형 AI] RAG (Retrieval-Augmented Generation) 개요(0) | 2025.02.17\\\\n[생성형 AI] GPT 개념(2) | 2025.02.16\\\\n[생성형 AI] Transformer 구조(0) | 2025.02.16\\\\n태그\\\\n\\\\n관련글\\\\n\\\\n최근글\\\\n\\\\n인기글\\\\n\\\\n전체 방문자\\\\n\\\\n25,833\\\\n\\\\nToday : 18\\\\n\\\\nYesterday : 90\\\\n\\\\nDesigned by 티스토리\\\\n\\\\n© Kakao Corp.\\\\n\\\\n티스토리툴바\\\\n\\\\n\\\\n\\\\n\", \"images\": []}, {\"url\": \"https://dytis.tistory.com/95\", \"raw_content\": \"\\\\n\\\\nLLM 어플리케이션에서의 Tool Calling: AI가 더 똑똑해지는 방법\\\\n\\\\nLLM(대형 언어 모델) 어플리케이션이 갈수록 더 많은 일들을 할 수 있게 되면서, \\\\\"Tool calling\\\\\" 기능은 그중에서도 가장 주목할 만한 혁신 중 하나로 자리 잡고 있습니다. 이 기능은 AI가 외부의 도구나 서비스에 접근하여 문제를 해결하거나 정보를 가져오는 능력을 의미합니다. 이번 글에서는 Tool calling이 무엇인지, 어떻게 LLM 어플리케이션의 활용성을 확장하는지에 대해 살펴보겠습니다.\\\\n\\\\n\\\\n\\\\nTool Calling이란?\\\\n\\\\nTool calling은 LLM이 외부 도구나 API와 상호작용할 수 있는 기능입니다. LLM은 매우 강력하지만, 단독으로는 모든 작업을 수행하는 데 한계가 있습니다.\\\\n\\\\nLLM은 훈련된 데이터에 포함된 지식만을 활용할 수 있기 때문에 훈련 이후에 발생한 새로운 사건이나 정보를 알지 못합니다. 또한, LLM은 확률적으로 답변을 생성하기 때문에 고정된 규칙을 따르는 작업, 예를 들어 수학 계산 같은 경우에는 부정확할 수 있습니다.\\\\n\\\\n또한, LLM을 다른 시스템과 프로그램적으로 연결하여 \\'Plug-and-Play\\' 방식으로 사용하기에는 어려움이 있습니다. LLM은 자연어를 사용하여 소통하기 때문에 해석의 여지가 많아 모호할 수 있지만, 다른 소프트웨어나 애플리케이션은 사전 정의된 고정된 형식의 코드와 인터페이스를 통해 소통합니다.\\\\n\\\\n이러한 문제를 해결하기 위해 Tool calling은 LLM과 다른 시스템이 상호작용할 수 있는 공통 프로토콜을 제공합니다. 이 절차는 주로 다음과 같은 방식으로 이루어집니다:\\\\n\\\\nLLM이 이 프로토콜을 이해하고 따르는 방법은 다양합니다. 중요한 것은 LLM이 이러한 도구 호출을 가능하게 하는 프롬프트 엔지니어링이나 사전에 내장된 템플릿을 활용한다는 점입니다. Tool calling은 LLM이 자체 데이터베이스에만 의존하지 않고, 외부 소스에서 최신 정보나 특정 기능을 가져올 수 있도록 해줍니다. 예를 들어 계산기 기능을 호출하거나, 웹사이트에서 최신 정보를 검색하거나, 데이터베이스에서 특정한 데이터를 추출하는 일이 가능해집니다.\\\\n\\\\n간단히 말해, Tool calling은 LLM이 내부 지식만으로는 해결할 수 없는 문제를 풀기 위해 외부 자원을 \\'도구\\'처럼 활용하는 방법입니다. 이는 마치 인간이 특정 작업을 할 때 필요한 도구를 사용하는 것과 유사합니다.\\\\n\\\\n\\\\n\\\\nTool Calling의 작동 방식\\\\n\\\\nTool calling은 주로 다음과 같은 방식으로 작동합니다:\\\\n\\\\n\\\\n\\\\nTool Calling의 장점\\\\n\\\\n실시간성: LLM이 최신 정보를 다룰 수 있도록 해줍니다. 정적 데이터로 한정되지 않고, 필요한 경우 실시간 데이터를 가져와 더 정확한 답변을 제공합니다.\\\\n\\\\n기능 확장성: 훈련 데이터에서 벗어난 복잡한 작업이나 도메인 특화 작업을 외부 도구와 연계하여 수행할 수 있습니다.\\\\n\\\\n자동화된 워크플로우 지원: 반복적인 작업이나 특정 프로세스를 자동화함으로써 사용자가 LLM과 상호작용할 때 생산성을 크게 향상시킬 수 있습니다.\\\\n\\\\n\\\\n\\\\nRAG 와는 어떻게 다를까?\\\\n\\\\nTool calling과 RAG(Retrieval-Augmented Generation)는 모두 LLM의 기능을 확장하는 중요한 방법이지만 그 접근 방식이 다릅니다. Tool calling은 LLM이 외부 도구나 API를 호출하여 특정 작업을 수행하는 방식인 반면, RAG는 외부 데이터베이스에서 정보를 검색하고 이를 활용하여 답변을 생성하는 방식입니다.\\\\n\\\\nRAG는 특히 많은 양의 정보를 검색하고 요약하는 데 강점을 가지며, 훈련 데이터에 포함되지 않은 정보를 실시간으로 검색하여 보다 풍부하고 정확한 답변을 제공합니다. 반면 Tool calling은 정보 검색을 넘어 실제 작업(예: 계산 수행, 이메일 전송 등)을 수행할 수 있도록 함으로써 더 다양한 기능을 지원합니다.\\\\n\\\\nTool calling은 LLM의 한계를 넘어 더 똑똑하고 유용한 AI를 만드는 데 중요한 역할을 하고 있습니다. 이 기능은 AI가 단순히 지식을 전달하는 것을 넘어서, 실제 작업을 수행하는 진정한 도우미로 발전하게 하는 핵심 요소입니다. 앞으로 더 다양한 도구와의 연동이 가능해지면서, LLM의 응용 범위는 더욱 확장될 것입니다.\\\\n\\\\n예를 들어, 의료 진단 도구와의 연계로 환자 데이터 분석을 돕거나, 금융 서비스와 연계해 고객 맞춤형 금융 컨설팅을 제공하는 등, 다양한 산업 분야에서의 응용 가능성을 기대할 수 있습니다.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nExample: OpenAI CookBook\\\\n\\\\nOpenAI CookBook에서 소개하는 Tool calling의 실제 적용 사례는 쇼핑 어시스턴트, 고객 서비스 에이전트, 그리고 인터랙티브 예약 경험입니다.\\\\n\\\\n\\\\n\\\\n쇼핑 어시스턴트\\\\n\\\\n쇼핑 어시스턴트는 사용자가 e-커머스 사이트를 탐색하면서 제품 데이터를 구조화된 데이터베이스에서 가져와 추천을 제공하고, 사용자가 관심 있는 제품을 찾으면 이를 장바구니에 추가하는 역할을 합니다. 이를 위해, 제품 데이터베이스를 쿼리하고, 특정 제품에 대한 리뷰나 재료, 크기 등의 추가 정보를 가져오며, 장바구니에 항목을 추가하는 도구가 필요합니다. 이 과정에서 사용되는 함수들은 다음과 같습니다:\\\\n\\\\n\\\\n\\\\n고객 서비스 에이전트\\\\n\\\\n고객 서비스 에이전트는 e-커머스 사이트에서 사용자가 구매 후 도움을 받을 수 있도록 돕습니다. 주문 관련 질문에 답변하거나, 반품 및 환불에 대한 회사 정책을 안내하며, 반품 처리를 돕고 상태 업데이트를 제공합니다. 이를 위해 주문 데이터베이스에서 세부 정보를 가져오고, 사용자가 주문 번호를 모를 경우에는 최근 주문 내역을 조회할 수 있어야 하며, FAQ 검색을 통해 일반적인 질문에 응답하고 반품 처리를 위한 도구와 반품 상태를 확인하는 기능도 필요합니다. 이 과정에서 사용되는 함수들은 다음과 같습니다:\\\\n\\\\n\\\\n\\\\n인터랙티브 예약 경험\\\\n\\\\n인터랙티브 예약 경험에서는 사용자가 식사하거나 머무를 장소를 찾기 위해 웹사이트를 이용하며, 사용자가 선호 사항을 언급하면 웹사이트는 지도에 추천 장소를 표시합니다. 사용자가 관심 있는 장소를 찾으면 예약이 자동으로 진행됩니다. 이 과정에서 사용자의 선호 사항에 따라 추천 정보를 가져오고 이를 지도에 핀으로 표시하며, 해당 장소의 이용 가능 여부를 조회하고 예약을 진행하는 기능이 필요합니다. 이 과정에서 사용되는 함수들은 다음과 같습니다:\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nHow-to: LangChain Tool Calling\\\\n\\\\nLangChain을 사용한 Tool calling은 LLM을 실질적으로 활용하는 데 있어 강력한 프레임워크를 제공합니다. LangChain은 다양한 도구와의 연계를 쉽게 만들어 주며, 이를 통해 복잡한 작업을 자동화하거나 외부 데이터와의 통합을 가능하게 합니다. Tool calling 기능은 LangChain의 핵심적인 구성 요소 중 하나로, LLM이 단순한 대화형 모델을 넘어 다양한 작업을 수행할 수 있도록 돕습니다.\\\\n\\\\n\\\\n\\\\nKey Concepts\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nRecommended usage\\\\n\\\\n다음은 Tool calling을 사용하는 권장 워크플로우를 설명하는 의사 코드입니다. 생성된 도구들은 .bind_tools() 메서드에 리스트 형태로 전달됩니다. 이렇게 바인딩된 모델은 평소와 같이 호출할 수 있으며, 도구 호출이 필요한 경우 모델의 응답에는 해당 도구 호출 인수가 포함됩니다. 이 도구 호출 인수는 직접적으로 도구에 전달되어 실행됩니다.\\\\n\\\\n\\\\n\\\\n1) Tool creation\\\\n\\\\nTool을 생성하는 데 권장되는 방법은 @tool 데코레이터를 사용하는 것입니다.\\\\n\\\\n\\\\n\\\\n2) Tool binding\\\\n\\\\n다양한 모델 제공자들이 도구 호출 기능을 지원합니다. LangChain의 핵심 개념은 도구와 모델을 연결하기 위한 표준화된 인터페이스를 제공한다는 점입니다. .bind_tools() 메서드를 사용하여 특정 모델이 호출할 수 있는 도구를 지정할 수 있습니다.\\\\n\\\\n예를 들어, multiply라는 함수를 도구로 만들어 도구 호출을 지원하는 모델에 바인딩하는 과정을 생각해 볼 수 있습니다.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n3) Tool calling\\\\n\\\\nTool calling의 핵심 원칙 중 하나는 입력의 관련성에 따라 모델이 도구를 사용할지 여부를 결정한다는 점입니다. 모델은 항상 도구를 호출할 필요가 없습니다. 예를 들어, 관련 없는 입력이 주어진 경우, 모델은 도구를 호출하지 않을 것입니다:\\\\n\\\\n이 경우 결과는 자연어로 된 모델의 응답을 포함하는 AIMessage가 될 것입니다(예: \\\\\"Hello!\\\\\"). 그러나 도구와 관련된 입력을 전달하면, 모델은 이를 호출해야 합니다:\\\\n\\\\n이전과 마찬가지로 출력 결과는 AIMessage가 될 것입니다. 하지만 도구가 호출된 경우, 결과에는 tool_calls 속성이 포함됩니다. 이 속성은 도구 실행에 필요한 모든 정보를 포함하며, 도구 이름과 입력 인수도 여기에 포함됩니다.\\\\n\\\\n\\\\n\\\\n4) Tool execution\\\\n\\\\nTool은 Runnable 인터페이스를 구현하기 때문에 직접 호출될 수 있습니다(예: tool.invoke(args)). LangGraph는 미리 구축된 구성 요소들(예: ToolNode)을 제공하여 사용자를 대신해 도구를 자주 호출합니다.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nTemplate: Qwen2.5의 Function Calling Templates\\\\n\\\\n기본적으로 function calling 또는 tool calling의 경우, llm의 시스템 메세지에 스키마를 포함합니다. 아래는 Qwen2.5의 function calling template 예시입니다.\\\\n\\\\n\\\\n\\\\n위의 프롬프트를 분리해보면 아래와 같이 이루어져 있습니다.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nBest Practices\\\\n\\\\nTool calling을 효과적으로 활용하기 위해 다음과 같은 모범 사례를 따르는 것이 좋습니다:\\\\n\\\\n구조화된 출력(Structured Outputs) 활성화: strict: \\\\\"true\\\\\"로 설정하여 구조화된 출력을 활성화하세요. 구조화된 출력이 켜져 있으면, 모델이 함수 호출을 위해 생성하는 인수가 제공된 JSON Schema와 일치하게 됩니다. 구조화된 출력을 사용하지 않을 경우, 인수의 구조가 항상 올바르다고 보장할 수 없으므로, Pydantic과 같은 검증 라이브러리를 사용하여 인수를 검증하는 것이 좋습니다.\\\\n\\\\n함수 이름과 설명의 직관적인 명명: 모델이 올바른 함수를 호출하지 못한다면, 함수 이름과 설명을 업데이트하여 모델이 언제 각 함수를 선택해야 하는지 더 명확히 이해하도록 해야 합니다. 함수 및 인수 이름을 줄이기 위해 약어나 두문자어를 사용하는 것은 피하세요. 또한, 함수 호출 시점에 대한 자세한 설명을 포함할 수 있습니다. 복잡한 함수의 경우, 모델이 사용자로부터 어떤 인수를 수집해야 하는지 이해할 수 있도록 각 인수에 대한 설명도 포함해야 합니다.\\\\n\\\\n함수 매개변수의 직관적인 명명과 상세한 설명: 함수 매개변수에 대해 명확하고 설명적인 이름을 사용하세요. 필요하다면 설명에서 매개변수의 예상 형식(예: 날짜의 경우 YYYY-mm-dd 또는 dd/mm/yy)을 지정하는 것이 좋습니다.\\\\n\\\\n시스템 메시지에 추가 정보 제공: 시스템 메시지에 명확한 지침을 제공하면 모델의 함수 호출 정확도를 크게 향상시킬 수 있습니다. 예를 들어, 다음과 같은 지침을 통해 모델을 안내할 수 있습니다: \\\\\"사용자가 주문 상태에 대해 문의할 때, 예를 들어 \\'내 주문이 어디에 있나요?\\' 또는 \\'내 주문이 발송되었나요?\\'와 같은 질문이 들어오면 check_order_status를 사용하세요.\\\\\" 복잡한 시나리오의 경우, 명확한 컨텍스트를 제공하는 것이 중요합니다. 예를 들어: \\\\\"schedule_meeting으로 회의를 예약하기 전에 check_availability를 사용하여 사용자의 캘린더에서 이용 가능 여부를 확인하여 중복 예약을 방지하세요.\\\\\"\\\\n\\\\n함수 인수에 가능한 경우 열거형(enum) 사용: 열거형을 사용해 인수의 가능한 값을 제한할 수 있다면, 이는 환각(hallucination)을 줄이는 데 도움이 됩니다. 예를 들어, AI 어시스턴트가 티셔츠 주문을 도울 때, 고정된 사이즈 세트를 사용할 수 있습니다. \\\\\"s\\\\\", \\\\\"m\\\\\", \\\\\"l\\\\\" 등으로 사이즈를 지정해 모델이 이 값을 선택하도록 할 수 있습니다. 특정 구조를 기대하는 경우, 가능한 값을 제한하는 것이 유리합니다.\\\\n\\\\n함수의 수를 줄여 정확도 향상: 단일 API 호출에서 사용되는 도구의 수를 20개 이하로 유지하는 것이 좋습니다. 도구가 10-20개 이상 정의된 경우, 모델이 올바른 도구를 선택하는 능력이 감소할 수 있습니다. 많은 수의 커스텀 함수를 선택해야 하는 경우, 도구를 그룹화하거나 멀티 에이전트 시스템을 만드는 방안을 고려해 볼 수 있습니다.\\\\n\\\\n프롬프트 엔지니어링 평가 시스템 설정: 함수 호출을 비단순하게 사용하는 경우, 평가 시스템을 설정하여 올바른 함수가 얼마나 자주 호출되었는지, 다양한 사용자 메시지에 대해 올바른 인수가 얼마나 자주 생성되었는지를 측정하는 것이 좋습니다. 이를 통해 함수 정의와 시스템 메시지에 대한 조정이 통합을 개선하는지 평가할 수 있습니다.\\\\n\\\\nFine-tuning 사용 고려: 많은 수의 함수가 있거나 복잡하고 미묘한 차이가 있는 함수의 경우, \\\\bfine-tuning이 함수 호출의 성능을 향상시키는 데 도움이 될 수 있습니다.\\\\n\\\\n\\'AI > 어플리케이션 개발\\' 카테고리의 다른 글\\\\n\\\\nLangChain을 활용한 Tool Calling # 2(3) | 2024.11.29\\\\nLangChain을 활용한 Tool Calling # 1(2) | 2024.11.29\\\\nLLM 애플리케이션 개발 훑어보기 - LangChain #3 Model I/O(1) | 2024.01.23\\\\nLLM 애플리케이션 개발 훑어보기 - LangChain #2 LangChain Expression Language (LCEL)(0) | 2024.01.22\\\\nLLM 애플리케이션 개발 훑어보기 - LangChain #1 Intro 및 QuickStart(0) | 2024.01.20\\\\n인기 글\\\\n\\\\n최근 댓글\\\\n\\\\n최근 글\\\\n\\\\n티스토리툴바\\\\n\\\\n\\\\n\\\\n\", \"images\": []}], \"failed_results\": [{\"url\": \"https://uracle.blog/2025/03/28/agent%EC%9D%98-%EA%B8%B0%EB%B0%98%EC%9D%B4-%EB%90%98%EB%8A%94-llm-tool-calling/\", \"error\": \"Access denied: Unable to retrieve content from the specified URL\"}, {\"url\": \"https://velog.io/@nylonmask/chat-completion-api-%EC%97%90%EC%84%A4%EC%9D%98-tool-calls\", \"error\": \"Failed to fetch content\"}], \"response_time\": 2.66}', name='tavily_extract', tool_call_id='fe7e93c3-542f-4a02-a356-825604f7fa93')]\n",
            "====agent response====\n",
            "content='AI 모델의 \"Tool Calling\"은 대규모 언어 모델(LLM)이 자체적인 지식 기반의 한계를 넘어 외부 도구, API, 데이터베이스 또는 코드 실행과 같은 외부 시스템과 상호작용하여 특정 작업을 수행하거나 실시간 정보를 얻는 기능입니다. 이는 LLM이 단순히 텍스트를 생성하는 것을 넘어, 실제 세계와 연동하여 더 복잡하고 동적인 문제를 해결할 수 있도록 돕습니다. LLM은 도구를 직접 실행하는 것이 아니라, 어떤 도구를 어떤 매개변수로 호출해야 하는지 추론하고 그 요청을 생성하며, 실제 도구 실행은 애플리케이션 로직에 의해 이루어집니다. [1], [2], [3], [4], [5], [7], [8]\\n\\n**작동 원리**\\nTool Calling의 작동 원리는 일반적으로 다음과 같은 메시지 흐름을 따릅니다. [5], [7]\\n1.  **AIMessage (툴 호출 요청):** 사용자의 질문을 받은 LLM이 자체적으로 답변을 생성하기 어렵거나 외부 정보가 필요하다고 판단하면, 호출할 도구의 이름과 필요한 매개변수를 포함하는 `tool_calls` 필드를 가진 메시지를 생성합니다. 이때 LLM은 도구를 직접 실행하지 않고, 단지 호출 요청만 만듭니다. [5], [7]\\n2.  **ToolMessage (툴 실행 및 결과 반환):** 애플리케이션은 LLM의 `tool_calls` 요청을 받아 실제 외부 도구(API 호출, 데이터베이스 조회, 코드 실행 등)를 실행합니다. 도구 실행이 완료되면, 그 결과는 `ToolMessage` 형태로 LLM에 다시 전달됩니다. [5], [7]\\n3.  **AIMessage (최종 응답 생성):** LLM은 `ToolMessage`를 통해 받은 도구 실행 결과를 바탕으로 사용자에게 최종적이고 정확한 자연어 응답을 생성합니다. [5], [7]\\n\\n**주요 이점**\\nTool Calling은 LLM의 활용성을 크게 확장하며 다음과 같은 이점을 제공합니다. [3], [7]\\n*   **실시간성 및 최신 정보 반영:** LLM이 학습된 정적 데이터에만 의존하지 않고, 외부 API를 통해 실시간 데이터를 가져와 최신 정보를 반영한 답변을 제공할 수 있습니다. (예: 현재 날씨, 주식 시세) [2], [3], [4], [7], [8]\\n*   **기능 확장성:** LLM이 직접 수행하기 어려운 복잡한 계산, 데이터베이스 쿼리, 외부 서비스 연동 등 다양한 도메인 특화 작업을 외부 도구와 연계하여 수행할 수 있습니다. [3], [4], [7]\\n*   **자동화된 워크플로우 지원:** 반복적인 작업이나 특정 프로세스를 자동화하여 사용자 생산성을 향상시키고, AI 에이전트가 더 능동적으로 문제를 해결하도록 돕습니다. [3]\\n*   **정확성 및 신뢰성 향상:** 확률적으로 답변을 생성하는 LLM의 한계를 보완하여, 고정된 규칙을 따르는 작업(예: 수학 계산)이나 정확한 정보가 필요한 경우에 외부 도구를 통해 신뢰할 수 있는 결과를 얻을 수 있습니다. [3], [4]\\n\\n**가장 일반적인 활용 분야 및 관련 프레임워크**\\n\\n**활용 분야/사례:**\\n1.  **실시간 정보 조회:** 현재 날씨, 주식 시세, 환율 정보 등 LLM의 학습 데이터에 없는 최신 정보를 외부 API를 통해 가져와 사용자에게 제공합니다. [2], [4], [6], [7], [8]\\n2.  **복잡한 계산 및 데이터 분석:** LLM이 직접 수행하기 어려운 수학 계산, 금융 데이터 분석(예: 주식 포트폴리오 가치 계산) 등을 외부 계산기 도구나 데이터 분석 라이브러리를 호출하여 처리합니다. [2], [4], [7], [8]\\n3.  **쇼핑 어시스턴트:** 제품 데이터베이스 쿼리, 특정 제품에 대한 리뷰/재료/크기 정보 가져오기, 장바구니에 항목 추가 등 전자상거래 관련 작업을 지원합니다. [3]\\n4.  **고객 서비스 에이전트:** 주문 관련 질문 답변, 반품 및 환불 정책 안내, 반품 처리, 주문 상태 업데이트 등 고객 지원 업무를 자동화합니다. [3]\\n5.  **인터랙티브 예약 시스템:** 사용자의 선호 사항에 따라 장소 추천, 이용 가능 여부 조회, 예약 진행 등 예약 관련 프로세스를 자동화합니다. [3]\\n6.  **AI 비서 및 검색 엔진:** 사용자의 질의에 따라 필요한 정보를 검색하고 요약하여 제공하거나, 특정 작업을 수행하는 AI 비서 역할을 합니다. [4]\\n7.  **전문 분야 응용:** 의료 진단 도구와 연계하여 환자 데이터 분석을 돕거나, 금융 서비스와 연계하여 고객 맞춤형 금융 컨설팅을 제공하는 등 다양한 산업 분야에 응용될 수 있습니다. [3], [4]\\n\\n**관련 프레임워크:**\\n*   **OpenAI Function Calling (또는 Tool Calling):** OpenAI 모델(예: GPT-4)이 자연어 요청을 이해하고 적합한 외부 API를 호출하여 실시간 정보를 가져오거나 특정 작업을 수행할 수 있도록 하는 기능입니다. Assistant API를 통해 함수 호출 기능을 통합하여 챗봇을 구현할 수 있습니다. [3], [6]\\n*   **LangChain Tools:** LangChain은 LLM을 위한 오픈소스 프레임워크로, Tool Calling 기능을 통해 LLM이 다양한 외부 도구(API, 데이터베이스 등)와 쉽게 연동하여 복잡한 작업을 자동화하거나 외부 데이터를 통합할 수 있도록 지원합니다. `@tool` 데코레이터를 사용하여 함수를 도구로 정의하고, `.bind_tools()` 메서드를 통해 모델에 바인딩하여 사용합니다. [1], [3], [7], [8]\\n*   **Spring AI Tool Calling:** Spring AI 프레임워크에서 제공하는 기능으로, AI 모델이 특정 API나 도구를 직접 호출하여 데이터를 가져오거나 연산을 수행할 수 있도록 지원합니다. `@Tool` 및 `@ToolParam` 애노테이션을 사용하여 도구를 정의하고 AI 모델과 연동합니다. [2]\\n\\n---\\n**출처:**\\n[1] LangChain을 활용한 Tool Calling # 3 - DEV.DY - 티스토리, https://dytis.tistory.com/98\\n[2] Spring AI의 새로운 도구 호출 기능: AI와 API의 강력한 연동 방법! - digitalbourgeois.tistory.com, https://digitalbourgeois.tistory.com/885\\n[3] LLM 어플리케이션에서의 Tool Calling: AI가 더 똑똑해지는 방법 - DEV.DY - 티스토리, https://dytis.tistory.com/95\\n[4] [생성형 AI] LLM의 Tool Calling(도구 호출)이란? - Go for IT - 티스토리, https://claremont.tistory.com/entry/%EC%83%9D%EC%84%B1%ED%98%95-AI-LLM%EC%9D%98-Tool-Calling%EB%8F%84%EA%B5%AC-%ED%98%B8%EC%B6%9C%EC%9D%B4%EB%9E%80\\n[5] AIMessage, ToolMessage, Tool Calling 흐름 이해 - velog, https://velog.io/@byu0hyun/AIMessage-ToolMessage-Tool-Calling-%ED%9D%90%EB%A6%84-%EC%9D%B4%ED%95%B4\\n[6] Assistants API ‘함수 호출(Function calling)’ 도구를 활용한 최저가 확인 챗봇 구현하기 - AI&GameDev, https://aiandgamedev.com/ai/assistant-api-function-calling/\\n[7] Tool Calling for LLMs: A Detailed Tutorial | by Explore With Yasir | Medium, https://medium.com/@developer.yasir.pk/tool-calling-for-llms-a-detailed-tutorial-a2b4d78633e2\\n[8] LLM Agent 개발하기 (2) Tool Calling. 들어가기 앞서 - Medium, https://medium.com/@craftsangjae/llm-agent-%EA%B0%9C%EB%B0%9C%ED%95%98%EA%B8%B0-2-tool-calling-e87e664f23df' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'models/gemini-2.5-flash-preview-05-20', 'safety_ratings': []} id='run-b7b4f0d2-eb27-4c69-9841-ace11ce226db-0' usage_metadata={'input_tokens': 22208, 'output_tokens': 1915, 'total_tokens': 28718, 'input_token_details': {'cache_read': 0}}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-777257253de7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         )]\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minput_query\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m#디버그용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2737\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2738\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2739\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   2740\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2741\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2375\u001b[0m                 \u001b[0;31m# with channel updates applied only at the transition between steps.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2376\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2377\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2378\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2379\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    159\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    620\u001b[0m                     \u001b[0;31m# run in context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m                         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    374\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-d06e89265aef>\u001b[0m in \u001b[0;36mcall_supervisor\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_supervisor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mGraphState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupervisor_chain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"====supervisor====\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-d06e89265aef>\u001b[0m in \u001b[0;36mprediction_agent\u001b[0;34m(chain, message)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3032\u001b[0m                         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3033\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3034\u001b[0;31m                         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3035\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3036\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5414\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5415\u001b[0m     ) -> Output:\n\u001b[0;32m-> 5416\u001b[0;31m         return self.bound.invoke(\n\u001b[0m\u001b[1;32m   5417\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5418\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, code_execution, stop, **kwargs)\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 )\n\u001b[1;32m   1174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m     def _get_ls_params(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m         return cast(\n\u001b[1;32m    367\u001b[0m             \u001b[0;34m\"ChatGeneration\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    369\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    935\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    936\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m                 results.append(\n\u001b[0;32m--> 759\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    760\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_from_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m             result = self._generate(\n\u001b[0m\u001b[1;32m   1003\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m   1240\u001b[0m             \u001b[0mtool_choice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtool_choice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m         )\n\u001b[0;32m-> 1242\u001b[0;31m         response: GenerateContentResponse = _chat_with_retry(\n\u001b[0m\u001b[1;32m   1243\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mwrapped_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_post_retry_check_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry_state\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"RetryCallState\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_explicit_retry\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_run_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_action_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m                     \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;31m# Do not retry for these errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFailedPrecondition\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    869\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             )\n\u001b[0;32m--> 293\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremaining_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompression\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     ) -> Any:\n\u001b[0;32m--> 277\u001b[0;31m         response, ignored_call = self._with_call(\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36m_with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_FailureOutcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         call = self._interceptor.intercept_unary_unary(\n\u001b[0m\u001b[1;32m    330\u001b[0m             \u001b[0mcontinuation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_call_details\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/grpc.py\u001b[0m in \u001b[0;36mintercept_unary_unary\u001b[0;34m(self, continuation, client_call_details, request)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 },\n\u001b[1;32m     77\u001b[0m             )\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontinuation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_call_details\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogging_enabled\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: NO COVER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mresponse_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrailing_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36mcontinuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    313\u001b[0m             ) = _unwrap_client_call_details(new_details, client_call_details)\n\u001b[1;32m    314\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m                 response, call = self._thunk(new_method).with_call(\n\u001b[0m\u001b[1;32m    316\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36mwith_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1193\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m             \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_for_ready\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_registered_call_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m             )\n\u001b[0;32m-> 1162\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m             \u001b[0m_handle_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}