{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anskong/ai_ref_from_lessons/blob/main/LGCNS_LangChain_005.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  도구를 이용한 대화모델과의 상호작용\n"
      ],
      "metadata": {
        "id": "BW50A6kmgvyg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIMwSwaYgtZ0",
        "outputId": "79eddd41-d4a8-4158-ad79-0f8b7665d412"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m61.4/63.4 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/438.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.3/438.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/720.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m720.4/720.4 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# 1) 필수 패키지 설치 (LangChain 0.3.0 이상)\n",
        "!pip install --quiet --upgrade \"langchain-openai>=0.3.0\" \"langchain-core>=0.3.0\" openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) API 키 로드 (Colab의 Tools → Secrets에 등록된 값 사용)\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# API 키 등록\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# 3) 필요한 모듈 임포트\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "# 4) LLM 인스턴스 생성\n",
        "llm = ChatOpenAI(\n",
        "    openai_api_key=OPENAI_API_KEY,\n",
        "    model=\"gpt-4.1-nano\"  # 필요 시 모델 변경\n",
        ")\n",
        "\n",
        "# 5) 초기 메시지 구성\n",
        "messages = [\n",
        "    SystemMessage(\"당신의 이름은 하루입니다.\"),\n",
        "    HumanMessage(\"내 이름은 데이브입니다.\"),\n",
        "    AIMessage(\"안녕하세요. 데이브\"),\n",
        "    HumanMessage(\"하루, 포드의 라이트를 20도 왼쪽으로 돌려줘.\"),\n",
        "]\n",
        "\n",
        "# 6) Tool 정의 및 바인딩\n",
        "@tool\n",
        "def light_control(degrees: float) -> bool:\n",
        "    \"\"\"\n",
        "    조명을 오른쪽으로 degrees 만큼 회전시킵니다.\n",
        "    실제 하드웨어 대신 콘솔에 출력합니다.\n",
        "    \"\"\"\n",
        "    print(f\"[Tool 실행] 조명을 {degrees}도 회전시킴\")\n",
        "    return True\n",
        "\n",
        "llm_with_tool = llm.bind_tools([light_control])\n",
        "\n",
        "# 7) 첫 번째 모델 응답\n",
        "response = llm_with_tool.invoke(messages)\n",
        "messages.append(response)\n",
        "\n",
        "# 8) 툴 호출 처리\n",
        "if response.tool_calls:\n",
        "    for call in response.tool_calls:\n",
        "        value = light_control.invoke(call[\"args\"])\n",
        "        messages.append(ToolMessage(content=value, tool_call_id=call[\"id\"]))\n",
        "\n",
        "# 9) 후속 응답\n",
        "final_response = llm_with_tool.invoke(messages)\n",
        "\n",
        "# 10) 최종 출력\n",
        "print(\"=== 모델 최종 응답 ===\")\n",
        "print(final_response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rl80svFgwvb",
        "outputId": "fcf18118-2e80-4a76-c0c8-4a3c31ed7072"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Tool 실행] 조명을 20.0도 회전시킴\n",
            "=== 모델 최종 응답 ===\n",
            "포드의 라이트를 20도 왼쪽으로 돌렸어요.\n"
          ]
        }
      ]
    }
  ]
}